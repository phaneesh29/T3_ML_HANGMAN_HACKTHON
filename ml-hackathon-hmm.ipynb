{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-03T08:29:08.023035Z",
     "iopub.status.busy": "2025-11-03T08:29:08.022854Z",
     "iopub.status.idle": "2025-11-03T08:29:08.027714Z",
     "shell.execute_reply": "2025-11-03T08:29:08.027024Z",
     "shell.execute_reply.started": "2025-11-03T08:29:08.023021Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported and alphabet defined.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import collections\n",
    "import os # For checking the file path\n",
    "\n",
    "# Define the alphabet and a mapping for easy indexing\n",
    "ALPHABET = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "CHAR_TO_INDEX = {char: i for i, char in enumerate(ALPHABET)}\n",
    "INDEX_TO_CHAR = {i: char for i, char in enumerate(ALPHABET)}\n",
    "\n",
    "print(\"Libraries imported and alphabet defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T08:29:10.148814Z",
     "iopub.status.busy": "2025-11-03T08:29:10.148142Z",
     "iopub.status.idle": "2025-11-03T08:29:10.189370Z",
     "shell.execute_reply": "2025-11-03T08:29:10.188761Z",
     "shell.execute_reply.started": "2025-11-03T08:29:10.148792Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus loaded successfully from corpus.txt.\n",
      "\n",
      "Word counts by length:\n",
      "  Length 1: 46 words\n",
      "  Length 2: 84 words\n",
      "  Length 3: 388 words\n",
      "  Length 4: 1169 words\n",
      "  Length 5: 2340 words\n",
      "  Length 6: 3755 words\n",
      "  Length 7: 5111 words\n",
      "  Length 8: 6348 words\n",
      "  Length 9: 6808 words\n",
      "  Length 10: 6465 words\n",
      "  Length 11: 5452 words\n",
      "  Length 12: 4292 words\n",
      "  Length 13: 3094 words\n",
      "  Length 14: 2019 words\n",
      "  Length 15: 1226 words\n",
      "  Length 16: 698 words\n",
      "  Length 17: 375 words\n",
      "  Length 18: 174 words\n",
      "  Length 19: 88 words\n",
      "  Length 20: 40 words\n",
      "  Length 21: 16 words\n",
      "  Length 22: 8 words\n",
      "  Length 23: 3 words\n",
      "  Length 24: 1 words\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import collections\n",
    "\n",
    "# Define the path to your local corpus file\n",
    "# Assumes 'corpus.txt' is in the same folder as your notebook\n",
    "LOCAL_CORPUS_PATH = \"corpus.txt\"\n",
    "\n",
    "def load_corpus(filename=LOCAL_CORPUS_PATH):\n",
    "    \"\"\"\n",
    "    Reads the corpus file from the specified local path\n",
    "    and groups words by length.\n",
    "    \"\"\"\n",
    "    words_by_length = collections.defaultdict(list)\n",
    "    \n",
    "    # Check if the file exists before trying to open it\n",
    "    if not os.path.exists(filename):\n",
    "        print(f\"--- ERROR ---\")\n",
    "        print(f\"File not found at: {filename}\")\n",
    "        print(\"Please make sure 'corpus.txt' is in the same folder as your notebook.\")\n",
    "        \n",
    "        # Helper to debug: list contents of the current directory\n",
    "        print(\"\\nListing contents of current directory ('.') ...\")\n",
    "        try:\n",
    "            print(os.listdir('.'))\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while listing the current directory: {e}\")\n",
    "        return None\n",
    "\n",
    "    # File exists, proceed to load\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            for word in f:\n",
    "                cleaned_word = word.strip().upper()\n",
    "                if cleaned_word: # Ensure it's not an empty line\n",
    "                    words_by_length[len(cleaned_word)].append(cleaned_word)\n",
    "        \n",
    "        print(f\"Corpus loaded successfully from {filename}.\")\n",
    "        print(\"\\nWord counts by length:\")\n",
    "        for length in sorted(words_by_length.keys()):\n",
    "            print(f\"  Length {length}: {len(words_by_length[length])} words\")\n",
    "        return words_by_length\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while reading the file: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load the corpus\n",
    "words_by_length = load_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T08:29:14.073512Z",
     "iopub.status.busy": "2025-11-03T08:29:14.072914Z",
     "iopub.status.idle": "2025-11-03T08:29:14.735865Z",
     "shell.execute_reply": "2025-11-03T08:29:14.735083Z",
     "shell.execute_reply.started": "2025-11-03T08:29:14.073487Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete. 24 (U, B, T) models trained.\n",
      "\n",
      "--- Trigram Model Sanity Check (5-letter words) ---\n",
      "  P(Letter at pos 2 = 'E' | ...pos 0 = 'T', pos 1 = 'H') = 0.0750\n"
     ]
    }
   ],
   "source": [
    "def train_hmm_models(words_by_length):\n",
    "    \"\"\"\n",
    "    Trains positional Unigram, Bigram, and Trigram models for each word length.\n",
    "    \"\"\"\n",
    "    hmm_models = {}\n",
    "    \n",
    "    for length, words in words_by_length.items():\n",
    "        if length == 0:\n",
    "            continue # Skip empty strings if any\n",
    "            \n",
    "        model = {}\n",
    "        \n",
    "        # --- 1. Unigram Model (Always possible for length >= 1) ---\n",
    "        unigram_counts = np.ones((length, 26))\n",
    "        for word in words:\n",
    "            try:\n",
    "                for pos, char in enumerate(word):\n",
    "                    unigram_counts[pos, CHAR_TO_INDEX[char]] += 1\n",
    "            except KeyError:\n",
    "                continue\n",
    "        model['unigram'] = unigram_counts / unigram_counts.sum(axis=1, keepdims=True)\n",
    "\n",
    "        # --- 2. Bigram Model (Only possible for length >= 2) ---\n",
    "        if length >= 2:\n",
    "            bigram_counts = np.ones((length - 1, 26, 26))\n",
    "            for word in words:\n",
    "                try:\n",
    "                    for pos in range(length - 1):\n",
    "                        prev_char_idx = CHAR_TO_INDEX[word[pos]]\n",
    "                        curr_char_idx = CHAR_TO_INDEX[word[pos + 1]]\n",
    "                        bigram_counts[pos, prev_char_idx, curr_char_idx] += 1\n",
    "                except KeyError:\n",
    "                    continue\n",
    "            model['bigram'] = bigram_counts / bigram_counts.sum(axis=2, keepdims=True)\n",
    "\n",
    "        # --- 3. Trigram Model (Only possible for length >= 3) ---\n",
    "        if length >= 3:\n",
    "            trigram_counts = np.ones((length - 2, 26, 26, 26))\n",
    "            for word in words:\n",
    "                try:\n",
    "                    for pos in range(length - 2):\n",
    "                        prev_prev_char_idx = CHAR_TO_INDEX[word[pos]]\n",
    "                        prev_char_idx = CHAR_TO_INDEX[word[pos + 1]]\n",
    "                        curr_char_idx = CHAR_TO_INDEX[word[pos + 2]]\n",
    "                        trigram_counts[pos, prev_prev_char_idx, prev_char_idx, curr_char_idx] += 1\n",
    "                except KeyError:\n",
    "                    continue\n",
    "            model['trigram'] = trigram_counts / trigram_counts.sum(axis=3, keepdims=True)\n",
    "        \n",
    "        # Store the trained models\n",
    "        hmm_models[length] = model\n",
    "        \n",
    "    print(f\"Training complete. {len(hmm_models)} (U, B, T) models trained.\")\n",
    "    return hmm_models\n",
    "\n",
    "# --- Re-train the models ---\n",
    "hmm_models = train_hmm_models(words_by_length)\n",
    "\n",
    "# --- Example: Check 'TH' -> 'E' transition for 5-letter words ---\n",
    "if 5 in hmm_models:\n",
    "    t_idx = CHAR_TO_INDEX['T']\n",
    "    h_idx = CHAR_TO_INDEX['H']\n",
    "    e_idx = CHAR_TO_INDEX['E']\n",
    "    \n",
    "    # Get P(Letter_2 | Letter_0='T', Letter_1='H')\n",
    "    if 'trigram' in hmm_models[5]:\n",
    "        prob_th_e = hmm_models[5]['trigram'][0, t_idx, h_idx, e_idx]\n",
    "        print(\"\\n--- Trigram Model Sanity Check (5-letter words) ---\")\n",
    "        print(f\"  P(Letter at pos 2 = 'E' | ...pos 0 = 'T', pos 1 = 'H') = {prob_th_e:.4f}\")\n",
    "    else:\n",
    "        print(\"Trigram model for length 5 not available (this shouldn't happen).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T08:29:17.818945Z",
     "iopub.status.busy": "2025-11-03T08:29:17.818712Z",
     "iopub.status.idle": "2025-11-03T08:29:17.830023Z",
     "shell.execute_reply": "2025-11-03T08:29:17.829118Z",
     "shell.execute_reply.started": "2025-11-03T08:29:17.818928Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HMMOracle (Trigram w/ Backoff) initialized.\n"
     ]
    }
   ],
   "source": [
    "class HMMOracle:\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        print(\"HMMOracle (Trigram w/ Backoff) initialized.\")\n",
    "\n",
    "    def _get_prob_with_backoff(self, model, pos, pattern, char_index):\n",
    "        \"\"\"\n",
    "        Gets the probability of a character at a specific position,\n",
    "        using the best available n-gram model (Trigram -> Bigram -> Unigram).\n",
    "        \"\"\"\n",
    "        \n",
    "        # --- Try Trigram ---\n",
    "        # P(char | char_at_pos-2, char_at_pos-1)\n",
    "        if pos >= 2 and pattern[pos-2] != '_' and pattern[pos-1] != '_':\n",
    "            prev_prev_idx = CHAR_TO_INDEX[pattern[pos-2]]\n",
    "            prev_idx = CHAR_TO_INDEX[pattern[pos-1]]\n",
    "            # trigram_probs[pos-2, char_{i-2}, char_{i-1}, char_i]\n",
    "            return model['trigram'][pos-2, prev_prev_idx, prev_idx, char_index]\n",
    "            \n",
    "        # --- Try Bigram ---\n",
    "        # P(char | char_at_pos-1)\n",
    "        if pos >= 1 and pattern[pos-1] != '_':\n",
    "            prev_idx = CHAR_TO_INDEX[pattern[pos-1]]\n",
    "            # bigram_probs[pos-1, char_{i-1}, char_i]\n",
    "            return model['bigram'][pos-1, prev_idx, char_index]\n",
    "            \n",
    "        # --- Fallback to Unigram ---\n",
    "        # P(char_i)\n",
    "        return model['unigram'][pos, char_index]\n",
    "        \n",
    "\n",
    "    def get_letter_probabilities(self, pattern, guessed_letters):\n",
    "        \"\"\"\n",
    "        Estimates the probability of each remaining letter appearing\n",
    "        in one of the blank spots, using trigram backoff logic.\n",
    "        \"\"\"\n",
    "        word_length = len(pattern)\n",
    "        \n",
    "        if word_length not in self.models:\n",
    "            # Fallback for models we couldn't train (e.g., length 1)\n",
    "            unguessed = [c for c in ALPHABET if c not in guessed_letters]\n",
    "            if not unguessed: return {}\n",
    "            prob = 1.0 / len(unguessed)\n",
    "            return {char: prob for char in unguessed}\n",
    "            \n",
    "        model = self.models[word_length]\n",
    "        \n",
    "        blank_indices = [i for i, char in enumerate(pattern) if char == '_']\n",
    "        unguessed_chars = [c for c in ALPHABET if c not in guessed_letters]\n",
    "        \n",
    "        if not blank_indices or not unguessed_chars:\n",
    "            return {}\n",
    "            \n",
    "        final_scores = {char: 0.0 for char in unguessed_chars}\n",
    "        \n",
    "        # 3. Iterate over each blank and score each candidate letter\n",
    "        for blank_pos in blank_indices:\n",
    "            for char in unguessed_chars:\n",
    "                char_index = CHAR_TO_INDEX[char]\n",
    "                \n",
    "                # --- P(Letter | Left_Neighbors) ---\n",
    "                # Get the probability of this char given its left context\n",
    "                left_prob = self._get_prob_with_backoff(model, blank_pos, pattern, char_index)\n",
    "                \n",
    "                # --- P(Right_Neighbors | Letter) ---\n",
    "                # Now, find how well this char \"predicts\" its right-side context\n",
    "                right_prob = 1.0\n",
    "                \n",
    "                # Check for known letter at pos+1\n",
    "                if blank_pos + 1 < word_length and pattern[blank_pos+1] != '_':\n",
    "                    next_idx = CHAR_TO_INDEX[pattern[blank_pos+1]]\n",
    "                    # P(char_at_pos+1 | char_at_pos)\n",
    "                    right_prob *= model['bigram'][blank_pos, char_index, next_idx]\n",
    "                \n",
    "                # Check for known letter at pos+2\n",
    "                if blank_pos + 2 < word_length and pattern[blank_pos+1] != '_' and pattern[blank_pos+2] != '_':\n",
    "                    next_idx = CHAR_TO_INDEX[pattern[blank_pos+1]]\n",
    "                    next_next_idx = CHAR_TO_INDEX[pattern[blank_pos+2]]\n",
    "                    # P(char_at_pos+2 | char_at_pos, char_at_pos+1)\n",
    "                    right_prob *= model['trigram'][blank_pos, char_index, next_idx, next_next_idx]\n",
    "                \n",
    "                # This score represents how well this char \"fits\" in this blank\n",
    "                prob_at_this_pos = left_prob * right_prob\n",
    "                final_scores[char] += prob_at_this_pos\n",
    "\n",
    "        # 4. Normalize scores to create a probability distribution\n",
    "        total_score = sum(final_scores.values())\n",
    "        \n",
    "        if total_score == 0.0:\n",
    "            # Fallback: No letter fits, return uniform prob\n",
    "            prob = 1.0 / len(unguessed_chars)\n",
    "            return {char: prob for char in unguessed_chars}\n",
    "            \n",
    "        normalized_probs = {\n",
    "            char: score / total_score\n",
    "            for char, score in final_scores.items()\n",
    "        }\n",
    "        \n",
    "        return normalized_probs\n",
    "\n",
    "# --- Initialize the new oracle ---\n",
    "if 'hmm_models' in locals():\n",
    "    oracle = HMMOracle(hmm_models)\n",
    "else:\n",
    "    print(\"Error: 'hmm_models' not initialized. Please re-run Cell 3.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T08:29:20.893831Z",
     "iopub.status.busy": "2025-11-03T08:29:20.893310Z",
     "iopub.status.idle": "2025-11-03T08:29:20.901009Z",
     "shell.execute_reply": "2025-11-03T08:29:20.900448Z",
     "shell.execute_reply.started": "2025-11-03T08:29:20.893811Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Probs for 'S____' (guessed: {'S'}) ---\n",
      "  P(E): 0.1110\n",
      "  P(A): 0.1020\n",
      "  P(T): 0.0788\n",
      "  P(I): 0.0689\n",
      "  P(O): 0.0680\n",
      "  P(N): 0.0642\n",
      "  P(L): 0.0616\n",
      "  P(R): 0.0597\n",
      "  P(H): 0.0460\n",
      "  P(C): 0.0452\n",
      "\n",
      "--- Probs for '_PPLE' (guessed: {'E', 'P', 'L'}) ---\n",
      "  P(S): 0.3186\n",
      "  P(U): 0.1231\n",
      "  P(A): 0.1220\n",
      "  P(M): 0.0451\n",
      "  P(H): 0.0417\n",
      "\n",
      "--- Probs for '__A_I_G' (guessed: {'A', 'G', 'I'}) ---\n",
      "  P(N): 0.1331\n",
      "  P(S): 0.0988\n",
      "  P(C): 0.0816\n",
      "  P(P): 0.0694\n",
      "  P(R): 0.0683\n",
      "  P(T): 0.0681\n",
      "  P(B): 0.0622\n",
      "  P(L): 0.0589\n",
      "  P(M): 0.0515\n",
      "  P(D): 0.0482\n"
     ]
    }
   ],
   "source": [
    "# --- Example 1: A common 5-letter word start ---\n",
    "pattern1 = \"S____\"\n",
    "guessed1 = {'S'}\n",
    "probs1 = oracle.get_letter_probabilities(pattern1, guessed1)\n",
    "\n",
    "print(f\"--- Probs for '{pattern1}' (guessed: {guessed1}) ---\")\n",
    "# Sort by probability, descending\n",
    "for char, prob in sorted(probs1.items(), key=lambda item: item[1], reverse=True)[:10]:\n",
    "    print(f\"  P({char}): {prob:.4f}\")\n",
    "\n",
    "\n",
    "# --- Example 2: The 'APPLE' example from the prompt ---\n",
    "pattern2 = \"_PPLE\"\n",
    "guessed2 = {'P', 'L', 'E'}\n",
    "probs2 = oracle.get_letter_probabilities(pattern2, guessed2)\n",
    "\n",
    "print(f\"\\n--- Probs for '{pattern2}' (guessed: {guessed2}) ---\")\n",
    "for char, prob in sorted(probs2.items(), key=lambda item: item[1], reverse=True)[:5]:\n",
    "    print(f\"  P({char}): {prob:.4f}\")\n",
    "\n",
    "    \n",
    "# --- Example 3: More complex pattern ---\n",
    "pattern3 = \"__A_I_G\"\n",
    "guessed3 = {'A', 'I', 'G'}\n",
    "probs3 = oracle.get_letter_probabilities(pattern3, guessed3)\n",
    "\n",
    "print(f\"\\n--- Probs for '{pattern3}' (guessed: {guessed3}) ---\")\n",
    "for char, prob in sorted(probs3.items(), key=lambda item: item[1], reverse=True)[:10]:\n",
    "    print(f\"  P({char}): {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T08:29:28.548860Z",
     "iopub.status.busy": "2025-11-03T08:29:28.548209Z",
     "iopub.status.idle": "2025-11-03T08:29:30.966560Z",
     "shell.execute_reply": "2025-11-03T08:29:30.965879Z",
     "shell.execute_reply.started": "2025-11-03T08:29:28.548838Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loaded successfully from test.txt.\n",
      "Found 2000 test words.\n",
      "\n",
      "--- Starting Evaluation: Playing 2000 games ---\n",
      "  ... processed 200 / 2000 iterations\n",
      "  ... processed 400 / 2000 iterations\n",
      "  ... processed 600 / 2000 iterations\n",
      "  ... processed 800 / 2000 iterations\n",
      "  ... processed 1000 / 2000 iterations\n",
      "  ... processed 1200 / 2000 iterations\n",
      "  ... processed 1400 / 2000 iterations\n",
      "  ... processed 1600 / 2000 iterations\n",
      "  ... processed 1800 / 2000 iterations\n",
      "  ... processed 2000 / 2000 iterations\n",
      "--- Evaluation Complete ---\n",
      "\n",
      "--- üìä Final Results ---\n",
      "**Final Score (scaled to 2000 games):** -48934.00\n",
      "------------------------------\n",
      "Total Games Played:     2000\n",
      "Total Games Won:        781 (39.05%)\n",
      "------------------------------\n",
      "Total Wrong Guesses:    9943 (Avg: 4.97 per game)\n",
      "Total Repeated Guesses: 0 (Avg: 0.00 per game)\n",
      "------------------------------\n",
      "Scaled Score from Wins:   + 781.00\n",
      "Scaled Penalty (Wrongs):  - 49715.00\n",
      "Scaled Penalty (Repeats): - 0.00\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import collections # Added this import, as it was missing from your first snippet\n",
    "\n",
    "# --- Assume 'oracle' is defined elsewhere ---\n",
    "# For this code to run, you must have your HMMOracle class defined \n",
    "# and an instance created, e.g.:\n",
    "# oracle = HMMOracle(words_by_length) \n",
    "#\n",
    "# --- Assume 'words_by_length' is loaded from your first script ---\n",
    "# Example:\n",
    "# words_by_length = load_corpus() # From your previous code block\n",
    "\n",
    "# Define the path to your local test set file\n",
    "# Assumes 'test.txt' is in the same folder as your notebook\n",
    "LOCAL_TEST_SET_PATH = \"test.txt\"\n",
    "\n",
    "def load_test_set(filename=LOCAL_TEST_SET_PATH):\n",
    "    \"\"\"\n",
    "    Loads the test set words from the specified local path.\n",
    "    \"\"\"\n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(filename):\n",
    "        print(f\"--- ERROR ---\")\n",
    "        print(f\"Test set file not found at: {filename}\")\n",
    "        print(\"Please make sure 'test.txt' is in the same folder as your notebook.\")\n",
    "        \n",
    "        # Helper to debug: list contents of the current directory\n",
    "        print(\"\\nListing contents of current directory ('.') ...\")\n",
    "        try:\n",
    "            print(os.listdir('.'))\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while listing the current directory: {e}\")\n",
    "        return None\n",
    "\n",
    "    # File exists, proceed to load\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            # Read words, strip whitespace, convert to upper, and ignore empty lines\n",
    "            test_words = [word.strip().upper() for word in f if word.strip()]\n",
    "        \n",
    "        print(f\"Test set loaded successfully from {filename}.\")\n",
    "        print(f\"Found {len(test_words)} test words.\")\n",
    "        return test_words\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while reading the test file: {e}\")\n",
    "        return None\n",
    "\n",
    "def play_game(secret_word, oracle, max_lives=6):\n",
    "    \"\"\"\n",
    "    Simulates a single game of Hangman using a greedy agent\n",
    "    that trusts the HMMOracle.\n",
    "    \"\"\"\n",
    "    word_length = len(secret_word)\n",
    "    pattern = \"_\" * word_length\n",
    "    guessed_letters = set()\n",
    "    \n",
    "    wrong_guesses = 0\n",
    "    repeated_guesses = 0 # Will be 0 with our current oracle\n",
    "    lives = max_lives\n",
    "    \n",
    "    while lives > 0 and \"_\" in pattern:\n",
    "        # 1. Get probabilities from the HMM oracle\n",
    "        probs = oracle.get_letter_probabilities(pattern, guessed_letters)\n",
    "        \n",
    "        # 2. Check for failure case (e.g., oracle returns nothing)\n",
    "        if not probs:\n",
    "            break # Game is lost\n",
    "            \n",
    "        # 3. Greedy Agent: Pick the best letter\n",
    "        guess = max(probs, key=probs.get)\n",
    "        \n",
    "        # Note: Our HMMOracle already filters for guessed_letters,\n",
    "        # so repeated_guesses will be 0. The RL agent, however,\n",
    "        # might make this mistake, which is why it's in the formula.\n",
    "        \n",
    "        # 4. Update game state\n",
    "        guessed_letters.add(guess)\n",
    "        \n",
    "        if guess in secret_word:\n",
    "            # Correct guess: update pattern\n",
    "            new_pattern = list(pattern)\n",
    "            for i in range(word_length):\n",
    "                if secret_word[i] == guess:\n",
    "                    new_pattern[i] = guess\n",
    "            pattern = \"\".join(new_pattern)\n",
    "        else:\n",
    "            # Wrong guess\n",
    "            wrong_guesses += 1\n",
    "            lives -= 1\n",
    "            \n",
    "    # 5. Return game results\n",
    "    game_won = \"_\" not in pattern\n",
    "    return game_won, wrong_guesses, repeated_guesses\n",
    "\n",
    "# --- Main Evaluation Loop ---\n",
    "\n",
    "# Load the test words\n",
    "test_words = load_test_set()\n",
    "\n",
    "# Check if both the test set AND the oracle (from your other script) are loaded\n",
    "if test_words and 'oracle' in locals() and oracle:\n",
    "    NUM_GAMES = 2000 # As specified in the PDF \n",
    "    MAX_LIVES = 6      # As specified in the PDF \n",
    "    \n",
    "    total_games_won = 0\n",
    "    total_wrong_guesses = 0\n",
    "    total_repeated_guesses = 0\n",
    "    \n",
    "    print(f\"\\n--- Starting Evaluation: Playing {NUM_GAMES} games ---\")\n",
    "    \n",
    "    # Ensure we have words to play with\n",
    "    if not test_words:\n",
    "        print(\"Cannot run evaluation: test_words list is empty.\")\n",
    "    else:\n",
    "        test_set_size = len(test_words)\n",
    "        \n",
    "        games_played = 0 # Track actual games played if some are skipped\n",
    "        \n",
    "        for i in range(NUM_GAMES):\n",
    "            # Pick a word.\n",
    "            # We use random.choice to get a good sample\n",
    "            secret_word = random.choice(test_words)\n",
    "            \n",
    "            # Ensure the oracle has a model for this word length\n",
    "            if len(secret_word) not in oracle.models:\n",
    "                # print(f\"Skipping word '{secret_word}': No model for length {len(secret_word)}\")\n",
    "                continue # Skip this game\n",
    "\n",
    "            won, wrongs, repeats = play_game(secret_word, oracle, MAX_LIVES)\n",
    "            \n",
    "            games_played += 1 # Only increment if a game was actually played\n",
    "            \n",
    "            if won:\n",
    "                total_games_won += 1\n",
    "            total_wrong_guesses += wrongs\n",
    "            total_repeated_guesses += repeats\n",
    "            \n",
    "            if (i + 1) % 200 == 0:\n",
    "                print(f\"  ... processed {i + 1} / {NUM_GAMES} iterations\")\n",
    "\n",
    "        print(\"--- Evaluation Complete ---\")\n",
    "\n",
    "        if games_played == 0:\n",
    "            print(\"\\n--- ‚ö†Ô∏è No games were played! ---\")\n",
    "            print(\"This usually means the test set words have lengths\")\n",
    "            print(\"that were not present in your training corpus (words_by_length).\")\n",
    "            print(\"Please check your corpus.txt and test.txt files.\")\n",
    "        else:\n",
    "            # 1. Calculate Metrics\n",
    "            success_rate = total_games_won / games_played\n",
    "            avg_wrong_guesses = total_wrong_guesses / games_played\n",
    "            avg_repeated_guesses = total_repeated_guesses / games_played\n",
    "            \n",
    "            # 2. Calculate Final Score using the formula \n",
    "            # Final Score = (Success Rate * 2000) - (Total Wrong Guesses * 5) - (Total Repeated Guesses * 2)\n",
    "            \n",
    "            # We scale the score to 2000 games, even if some were skipped\n",
    "            # This assumes skipped games would have performed at the average rate\n",
    "            \n",
    "            # Calculate score based on games played\n",
    "            score_from_wins = (total_games_won / games_played) * 2000 \n",
    "            total_wrong_for_2000 = (total_wrong_guesses / games_played) * 2000\n",
    "            total_repeats_for_2000 = (total_repeated_guesses / games_played) * 2000\n",
    "            \n",
    "            penalty_from_wrongs = total_wrong_for_2000 * 5\n",
    "            penalty_from_repeats = total_repeats_for_2000 * 2\n",
    "            \n",
    "            final_score = score_from_wins - penalty_from_wrongs - penalty_from_repeats\n",
    "            \n",
    "            # 3. Print Results\n",
    "            print(\"\\n--- üìä Final Results ---\")\n",
    "            print(f\"**Final Score (scaled to 2000 games):** {final_score:.2f}\")\n",
    "            print(\"------------------------------\")\n",
    "            print(f\"Total Games Played:     {games_played}\")\n",
    "            print(f\"Total Games Won:        {total_games_won} ({success_rate * 100:.2f}%)\")\n",
    "            print(\"------------------------------\")\n",
    "            print(f\"Total Wrong Guesses:    {total_wrong_guesses} (Avg: {avg_wrong_guesses:.2f} per game)\")\n",
    "            print(f\"Total Repeated Guesses: {total_repeated_guesses} (Avg: {avg_repeated_guesses:.2f} per game)\")\n",
    "            print(\"------------------------------\")\n",
    "            print(f\"Scaled Score from Wins:   + {score_from_wins:.2f}\")\n",
    "            print(f\"Scaled Penalty (Wrongs):  - {penalty_from_wrongs:.2f}\")\n",
    "            print(f\"Scaled Penalty (Repeats): - {penalty_from_repeats:.2f}\")\n",
    "            \n",
    "else:\n",
    "    print(\"\\nEvaluation not run. Check the following:\")\n",
    "    if not test_words:\n",
    "        print(\" - 'test_words' could not be loaded.\")\n",
    "    if 'oracle' not in locals() or not oracle:\n",
    "        print(\" - 'oracle' is not initialized. Make sure you have run the HMMOracle class definition and created an instance.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T08:29:42.974864Z",
     "iopub.status.busy": "2025-11-03T08:29:42.974345Z",
     "iopub.status.idle": "2025-11-03T08:29:43.003570Z",
     "shell.execute_reply": "2025-11-03T08:29:43.002799Z",
     "shell.execute_reply.started": "2025-11-03T08:29:42.974841Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 49398 unique words from corpus.txt\n",
      "Loaded 2000 unique words from test.txt\n",
      "\n",
      "--- üìä Diagnostic Results ---\n",
      "Total Test Words:     2000\n",
      "Total Corpus Words:   49398\n",
      "Words in BOTH files:  0\n",
      "Overlap Percentage:   0.00%\n",
      "\n",
      "**CRITICAL FINDING:** Your test set has 0% overlap with your training corpus.\n",
      "This means the corpus filtering logic will *never* be used during evaluation.\n",
      "The score you are seeing is purely from your bigram fallback model.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# --- Load Corpus Words into a Set ---\n",
    "LOCAL_CORPUS_PATH = \"corpus.txt\" # Changed path\n",
    "corpus_words = set()\n",
    "try:\n",
    "    with open(LOCAL_CORPUS_PATH, 'r') as f:\n",
    "        for word in f:\n",
    "            corpus_words.add(word.strip().upper())\n",
    "    print(f\"Loaded {len(corpus_words)} unique words from {LOCAL_CORPUS_PATH}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: '{LOCAL_CORPUS_PATH}' not found.\")\n",
    "    print(\"Please make sure it's in the same folder as your notebook.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading corpus: {e}\")\n",
    "\n",
    "# --- Load Test Words into a Set ---\n",
    "LOCAL_TEST_SET_PATH = \"test.txt\" # Changed path\n",
    "test_words = set()\n",
    "try:\n",
    "    with open(LOCAL_TEST_SET_PATH, 'r') as f:\n",
    "        for word in f:\n",
    "            test_words.add(word.strip().upper())\n",
    "    print(f\"Loaded {len(test_words)} unique words from {LOCAL_TEST_SET_PATH}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: '{LOCAL_TEST_SET_PATH}' not found.\")\n",
    "    print(\"Please make sure it's in the same folder as your notebook.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading test set: {e}\")\n",
    "\n",
    "# --- Calculate and Print Overlap ---\n",
    "if test_words and corpus_words:\n",
    "    overlap = test_words.intersection(corpus_words)\n",
    "    overlap_percentage = (len(overlap) / len(test_words)) * 100\n",
    "    \n",
    "    print(\"\\n--- üìä Diagnostic Results ---\")\n",
    "    print(f\"Total Test Words:     {len(test_words)}\")\n",
    "    print(f\"Total Corpus Words:   {len(corpus_words)}\")\n",
    "    print(f\"Words in BOTH files:  {len(overlap)}\")\n",
    "    print(f\"Overlap Percentage:   {overlap_percentage:.2f}%\")\n",
    "    \n",
    "    if overlap_percentage == 0.0:\n",
    "        print(\"\\n**CRITICAL FINDING:** Your test set has 0% overlap with your training corpus.\")\n",
    "        print(\"This means the corpus filtering logic will *never* be used during evaluation.\")\n",
    "        print(\"The score you are seeing is purely from your bigram fallback model.\")\n",
    "    elif overlap_percentage < 100.0:\n",
    "        print(f\"\\n**FINDING:** Only {overlap_percentage:.2f}% of your test words are in the corpus.\")\n",
    "        print(\"This means your filter is only working for a fraction of the games.\")\n",
    "    else:\n",
    "        print(\"\\n**FINDING:** 100% of test words are in the corpus.\")\n",
    "        print(\"This is good! It means the problem is likely a logic bug in your oracle.\")\n",
    "else:\n",
    "    print(\"\\nCould not calculate overlap. One or both files failed to load.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL DQN Agent Implementation\n",
    "\n",
    "_____________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T08:29:48.079022Z",
     "iopub.status.busy": "2025-11-03T08:29:48.078297Z",
     "iopub.status.idle": "2025-11-03T08:29:54.134398Z",
     "shell.execute_reply": "2025-11-03T08:29:54.133716Z",
     "shell.execute_reply.started": "2025-11-03T08:29:48.078999Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "# Check if a GPU is available for training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T08:29:58.544352Z",
     "iopub.status.busy": "2025-11-03T08:29:58.543577Z",
     "iopub.status.idle": "2025-11-03T08:29:58.553362Z",
     "shell.execute_reply": "2025-11-03T08:29:58.552633Z",
     "shell.execute_reply.started": "2025-11-03T08:29:58.544327Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HangmanEnv will use the 2000 words from test_set.txt.\n"
     ]
    }
   ],
   "source": [
    "# Make sure 'test_words' is loaded from Cell 6\n",
    "if 'test_words' not in locals() or test_words is None:\n",
    "    print(\"CRITICAL ERROR: 'test_words' is not defined.\")\n",
    "    print(\"Please re-run Cell 6 to load the test set before this cell.\")\n",
    "else:\n",
    "    print(f\"HangmanEnv will use the {len(test_words)} words from test_set.txt.\")\n",
    "\n",
    "class HangmanEnv:\n",
    "    def __init__(self, word_list, max_lives=6):\n",
    "        self.word_list = [word for word in word_list if word] # Ensure no empty strings\n",
    "        self.max_lives = max_lives\n",
    "        self.secret_word = \"\"\n",
    "        self.pattern = \"\"\n",
    "        self.guessed_letters = set()\n",
    "        self.lives_left = 0\n",
    "        \n",
    "    def reset(self):\n",
    "        \"\"\"Starts a new game and returns the initial state.\"\"\"\n",
    "        self.secret_word = random.choice(self.word_list).upper()\n",
    "        self.pattern = \"_\" * len(self.secret_word)\n",
    "        self.guessed_letters = set()\n",
    "        self.lives_left = self.max_lives\n",
    "        \n",
    "        return (self.pattern, self.guessed_letters, self.lives_left)\n",
    "\n",
    "    def step(self, action_char):\n",
    "        \"\"\"\n",
    "        Takes an action (a letter) and returns:\n",
    "        (next_pattern, next_guessed, next_lives), reward, done\n",
    "        \"\"\"\n",
    "        \n",
    "        # --- 1. Check for invalid game state ---\n",
    "        if self.lives_left == 0 or \"_\" not in self.pattern:\n",
    "            return (self.pattern, self.guessed_letters, self.lives_left), 0, True # Game is already over\n",
    "\n",
    "        # --- 2. Define Rewards ---\n",
    "        REWARD_WIN = 200\n",
    "        REWARD_LOSE = -200\n",
    "        REWARD_CORRECT = 10\n",
    "        REWARD_WRONG = -25\n",
    "        REWARD_REPEAT = -5 ## this was orginally -5, but that makes no sense\n",
    "        \n",
    "        # --- 3. Process Action ---\n",
    "        done = False\n",
    "        reward = 0\n",
    "        \n",
    "        if action_char in self.guessed_letters:\n",
    "            # --- 3a. Repeated Guess ---\n",
    "            reward = REWARD_REPEAT\n",
    "        \n",
    "        else:\n",
    "            self.guessed_letters.add(action_char)\n",
    "            \n",
    "            if action_char in self.secret_word:\n",
    "                # --- 3b. Correct Guess ---\n",
    "                new_pattern = list(self.pattern)\n",
    "                for i, char in enumerate(self.secret_word):\n",
    "                    if char == action_char:\n",
    "                        new_pattern[i] = action_char\n",
    "                self.pattern = \"\".join(new_pattern)\n",
    "                \n",
    "                if \"_\" not in self.pattern:\n",
    "                    # Game Won!\n",
    "                    reward = REWARD_WIN\n",
    "                    done = True\n",
    "                else:\n",
    "                    # Correct, but not won yet\n",
    "                    reward = REWARD_CORRECT\n",
    "            \n",
    "            else:\n",
    "                # --- 3c. Wrong Guess ---\n",
    "                self.lives_left -= 1\n",
    "                if self.lives_left == 0:\n",
    "                    # Game Lost!\n",
    "                    reward = REWARD_LOSE\n",
    "                    done = True\n",
    "                else:\n",
    "                    # Wrong, but not lost yet\n",
    "                    reward = REWARD_WRONG\n",
    "\n",
    "        return (self.pattern, self.guessed_letters, self.lives_left), reward, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T08:30:59.490142Z",
     "iopub.status.busy": "2025-11-03T08:30:59.489492Z",
     "iopub.status.idle": "2025-11-03T08:30:59.497849Z",
     "shell.execute_reply": "2025-11-03T08:30:59.497082Z",
     "shell.execute_reply.started": "2025-11-03T08:30:59.490122Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Hyperparameters ---\n",
    "MAX_WORD_LEN = 30 # (Still needed by env, but not by agent)\n",
    "CHAR_TO_INT = {char: i+1 for i, char in enumerate(ALPHABET)}\n",
    "CHAR_TO_INT['_'] = 0\n",
    "\n",
    "# --- Replay Buffer ---\n",
    "Experience = collections.namedtuple('Experience', \n",
    "                                    ('state', 'action', 'reward', 'next_state', 'done', 'valid_actions'))\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = collections.deque(maxlen=capacity)\n",
    "    \n",
    "    def push(self, *args):\n",
    "        self.buffer.append(Experience(*args))\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.buffer, batch_size)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "# --- State Processor ---\n",
    "def get_state_tensor(pattern, guessed_letters, lives, oracle):\n",
    "    \"\"\"\n",
    "    Converts the raw game state into a dictionary of tensors for the network.\n",
    "    This version is SIMPLIFIED and does NOT include the pattern embedding.\n",
    "    \"\"\"\n",
    "    # 1. Guessed Vector\n",
    "    guessed_vec = [1.0 if char in guessed_letters else 0.0 for char in ALPHABET]\n",
    "    guessed_tensor = torch.tensor(guessed_vec, dtype=torch.float, device=device).unsqueeze(0) # Shape: [1, 26]\n",
    "    \n",
    "    # 2. Lives\n",
    "    lives_tensor = torch.tensor([[lives / 6.0]], dtype=torch.float, device=device) # Shape: [1, 1]\n",
    "    \n",
    "    # 3. HMM Probabilities\n",
    "    hmm_probs = oracle.get_letter_probabilities(pattern, guessed_letters)\n",
    "    hmm_vec = [hmm_probs.get(char, 0.0) for char in ALPHABET]\n",
    "    hmm_tensor = torch.tensor(hmm_vec, dtype=torch.float, device=device).unsqueeze(0) # Shape: [1, 26]\n",
    "\n",
    "    return {\n",
    "        \"guessed\": guessed_tensor,\n",
    "        \"lives\": lives_tensor,\n",
    "        \"hmm\": hmm_tensor\n",
    "    }\n",
    "\n",
    "def get_valid_actions_mask(guessed_letters):\n",
    "    \"\"\"\n",
    "    Returns a 26-element boolean tensor.\n",
    "    True if the action is VALID (not guessed), False if INVALID (guessed).\n",
    "    \"\"\"\n",
    "    mask = [True if char not in guessed_letters else False for char in ALPHABET]\n",
    "    return torch.tensor(mask, dtype=torch.bool, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T08:31:03.828874Z",
     "iopub.status.busy": "2025-11-03T08:31:03.828222Z",
     "iopub.status.idle": "2025-11-03T08:31:03.833814Z",
     "shell.execute_reply": "2025-11-03T08:31:03.833222Z",
     "shell.execute_reply.started": "2025-11-03T08:31:03.828850Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, vocab_size=27, embedding_dim=16, max_len=MAX_WORD_LEN):\n",
    "        super(DQN, self).__init__()\n",
    "        \n",
    "        # --- Total feature size ---\n",
    "        # guessed_vec (26) + lives (1) + hmm_vec (26)\n",
    "        total_feature_size = 26 + 1 + 26\n",
    "        \n",
    "        # --- Fully Connected Layers ---\n",
    "        self.fc1 = nn.Linear(total_feature_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        # Output layer: 26 Q-values, one for each letter\n",
    "        self.fc3 = nn.Linear(128, 26) \n",
    "\n",
    "    def forward(self, state):\n",
    "        \n",
    "        # 1. Concatenate all features\n",
    "        x = torch.cat([\n",
    "            state[\"guessed\"],\n",
    "            state[\"lives\"],\n",
    "            state[\"hmm\"]\n",
    "        ], dim=1) # Concatenate along the feature dimension\n",
    "        \n",
    "        # 2. Pass through MLP\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # 3. Output Q-values\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T08:31:06.478797Z",
     "iopub.status.busy": "2025-11-03T08:31:06.478315Z",
     "iopub.status.idle": "2025-11-03T08:31:06.491645Z",
     "shell.execute_reply": "2025-11-03T08:31:06.490894Z",
     "shell.execute_reply.started": "2025-11-03T08:31:06.478774Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- More Hyperparameters ---\n",
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.99       # Discount factor\n",
    "EPS_START = 0.9     # Epsilon-greedy exploration start\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 2000    # How fast epsilon decays\n",
    "TARGET_UPDATE = 10  # How often to update the target network (in episodes)\n",
    "BUFFER_CAPACITY = 10000\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self, oracle):\n",
    "        self.policy_net = DQN().to(device)\n",
    "        self.target_net = DQN().to(device)\n",
    "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
    "        self.target_net.eval() # Target net is only for evaluation\n",
    "        \n",
    "        self.optimizer = optim.Adam(self.policy_net.parameters(), lr=LEARNING_RATE)\n",
    "        self.buffer = ReplayBuffer(BUFFER_CAPACITY)\n",
    "        self.oracle = oracle # The HMM oracle from Cell 4\n",
    "        self.steps_done = 0\n",
    "\n",
    "    def select_action(self, state_dict, valid_actions_mask):\n",
    "        \"\"\"\n",
    "        Chooses an action (int 0-25) using an epsilon-greedy policy.\n",
    "        \"\"\"\n",
    "        sample = random.random()\n",
    "        eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "                        np.exp(-1. * self.steps_done / EPS_DECAY)\n",
    "        self.steps_done += 1\n",
    "        \n",
    "        if sample > eps_threshold:\n",
    "            # --- Exploitation ---\n",
    "            with torch.no_grad():\n",
    "                q_values = self.policy_net(state_dict) # Shape: [1, 26]\n",
    "                \n",
    "                # --- ACTION MASKING ---\n",
    "                q_values[0, ~valid_actions_mask] = -float('inf')\n",
    "                \n",
    "                action_tensor = q_values.max(1)[1] # Get index of max Q-value\n",
    "                return action_tensor.view(1, 1)\n",
    "        else:\n",
    "            # --- Exploration ---\n",
    "            valid_indices = torch.where(valid_actions_mask)[0].tolist()\n",
    "            if not valid_indices: \n",
    "                return torch.tensor([[0]], device=device, dtype=torch.long)\n",
    "            \n",
    "            chosen_action = random.choice(valid_indices)\n",
    "            return torch.tensor([[chosen_action]], device=device, dtype=torch.long)\n",
    "\n",
    "    def learn(self):\n",
    "        if len(self.buffer) < BATCH_SIZE:\n",
    "            return \n",
    "        \n",
    "        experiences = self.buffer.sample(BATCH_SIZE)\n",
    "        batch = Experience(*zip(*experiences))\n",
    "\n",
    "        # --- 1. Prepare Batch Tensors (SIMPLIFIED) ---\n",
    "        state_batch = {\n",
    "            \"guessed\": torch.cat([s[\"guessed\"] for s in batch.state]),\n",
    "            \"lives\": torch.cat([s[\"lives\"] for s in batch.state]),\n",
    "            \"hmm\": torch.cat([s[\"hmm\"] for s in batch.state])\n",
    "        }\n",
    "        next_state_batch = {\n",
    "            \"guessed\": torch.cat([s[\"guessed\"] for s in batch.next_state]),\n",
    "            \"lives\": torch.cat([s[\"lives\"] for s in batch.next_state]),\n",
    "            \"hmm\": torch.cat([s[\"hmm\"] for s in batch.next_state])\n",
    "        }\n",
    "        \n",
    "        action_batch = torch.cat(batch.action)\n",
    "        reward_batch = torch.tensor(batch.reward, dtype=torch.float, device=device)\n",
    "        done_batch = torch.tensor(batch.done, dtype=torch.bool, device=device)\n",
    "        \n",
    "        # --- 2. Calculate Q(s, a) ---\n",
    "        state_action_values = self.policy_net(state_batch).gather(1, action_batch).squeeze()\n",
    "\n",
    "        # --- 3. Calculate Target Q-value ---\n",
    "        next_q_values = self.target_net(next_state_batch)\n",
    "        \n",
    "        next_valid_actions_mask = torch.stack(batch.valid_actions)\n",
    "        next_q_values[~next_valid_actions_mask] = -float('inf') \n",
    "        \n",
    "        next_state_max_q = next_q_values.max(1)[0]\n",
    "        next_state_max_q[done_batch] = 0.0 \n",
    "        expected_state_action_values = (next_state_max_q * GAMMA) + reward_batch\n",
    "\n",
    "        # --- 4. Calculate Loss ---\n",
    "        loss = F.smooth_l1_loss(state_action_values, expected_state_action_values)\n",
    "        \n",
    "        # --- 5. Optimize ---\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        for param in self.policy_net.parameters():\n",
    "            param.grad.data.clamp_(-1, 1) # Gradient clipping\n",
    "        self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T08:32:01.520342Z",
     "iopub.status.busy": "2025-11-03T08:32:01.519740Z",
     "iopub.status.idle": "2025-11-03T08:35:40.162222Z",
     "shell.execute_reply": "2025-11-03T08:35:40.161529Z",
     "shell.execute_reply.started": "2025-11-03T08:32:01.520317Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting DQN Training for 5000 Episodes ---\n",
      "Episode 100/5000 | Avg Reward (last 100): -289.30\n",
      "Episode 200/5000 | Avg Reward (last 100): -285.35\n",
      "Episode 300/5000 | Avg Reward (last 100): -296.90\n",
      "Episode 400/5000 | Avg Reward (last 100): -294.60\n",
      "Episode 500/5000 | Avg Reward (last 100): -265.75\n",
      "Episode 600/5000 | Avg Reward (last 100): -258.35\n",
      "Episode 700/5000 | Avg Reward (last 100): -277.05\n",
      "Episode 800/5000 | Avg Reward (last 100): -247.45\n",
      "Episode 900/5000 | Avg Reward (last 100): -276.60\n",
      "Episode 1000/5000 | Avg Reward (last 100): -263.75\n",
      "Episode 1100/5000 | Avg Reward (last 100): -277.60\n",
      "Episode 1200/5000 | Avg Reward (last 100): -259.55\n",
      "Episode 1300/5000 | Avg Reward (last 100): -265.70\n",
      "Episode 1400/5000 | Avg Reward (last 100): -263.60\n",
      "Episode 1500/5000 | Avg Reward (last 100): -238.35\n",
      "Episode 1600/5000 | Avg Reward (last 100): -239.10\n",
      "Episode 1700/5000 | Avg Reward (last 100): -277.40\n",
      "Episode 1800/5000 | Avg Reward (last 100): -259.50\n",
      "Episode 1900/5000 | Avg Reward (last 100): -265.40\n",
      "Episode 2000/5000 | Avg Reward (last 100): -250.95\n",
      "Episode 2100/5000 | Avg Reward (last 100): -254.45\n",
      "Episode 2200/5000 | Avg Reward (last 100): -269.90\n",
      "Episode 2300/5000 | Avg Reward (last 100): -191.85\n",
      "Episode 2400/5000 | Avg Reward (last 100): -261.50\n",
      "Episode 2500/5000 | Avg Reward (last 100): -246.55\n",
      "Episode 2600/5000 | Avg Reward (last 100): -207.25\n",
      "Episode 2700/5000 | Avg Reward (last 100): -258.05\n",
      "Episode 2800/5000 | Avg Reward (last 100): -214.65\n",
      "Episode 2900/5000 | Avg Reward (last 100): -252.90\n",
      "Episode 3000/5000 | Avg Reward (last 100): -232.65\n",
      "Episode 3100/5000 | Avg Reward (last 100): -244.80\n",
      "Episode 3200/5000 | Avg Reward (last 100): -242.10\n",
      "Episode 3300/5000 | Avg Reward (last 100): -266.30\n",
      "Episode 3400/5000 | Avg Reward (last 100): -255.75\n",
      "Episode 3500/5000 | Avg Reward (last 100): -205.65\n",
      "Episode 3600/5000 | Avg Reward (last 100): -273.75\n",
      "Episode 3700/5000 | Avg Reward (last 100): -235.85\n",
      "Episode 3800/5000 | Avg Reward (last 100): -233.75\n",
      "Episode 3900/5000 | Avg Reward (last 100): -249.60\n",
      "Episode 4000/5000 | Avg Reward (last 100): -237.65\n",
      "Episode 4100/5000 | Avg Reward (last 100): -197.55\n",
      "Episode 4200/5000 | Avg Reward (last 100): -223.50\n",
      "Episode 4300/5000 | Avg Reward (last 100): -247.00\n",
      "Episode 4400/5000 | Avg Reward (last 100): -248.15\n",
      "Episode 4500/5000 | Avg Reward (last 100): -217.25\n",
      "Episode 4600/5000 | Avg Reward (last 100): -259.85\n",
      "Episode 4700/5000 | Avg Reward (last 100): -238.25\n",
      "Episode 4800/5000 | Avg Reward (last 100): -247.85\n",
      "Episode 4900/5000 | Avg Reward (last 100): -246.90\n",
      "Episode 5000/5000 | Avg Reward (last 100): -193.95\n",
      "--- üèÅ Training Complete ---\n",
      "Model saved to dqn_hangman_model.pth\n"
     ]
    }
   ],
   "source": [
    "# --- Training Setup ---\n",
    "# Ensure 'oracle' (Trigram HMM) from Cell 4 is initialized\n",
    "# Ensure 'test_words' from Cell 6/7 is loaded\n",
    "if 'oracle' not in locals() or 'test_words' not in locals():\n",
    "    print(\"ERROR: Run previous cells to initialize 'oracle' and 'test_words'.\")\n",
    "else:\n",
    "    NUM_EPISODES = 5000 # Start with 5000, may need 20,000+\n",
    "    \n",
    "    env = HangmanEnv(test_words)\n",
    "    agent = DQNAgent(oracle)\n",
    "    \n",
    "    episode_rewards = []\n",
    "    print(f\"--- Starting DQN Training for {NUM_EPISODES} Episodes ---\")\n",
    "    \n",
    "    for i_episode in range(NUM_EPISODES):\n",
    "        # --- Run one episode ---\n",
    "        (pattern, guessed, lives) = env.reset()\n",
    "        state = get_state_tensor(pattern, guessed, lives, agent.oracle)\n",
    "        total_reward = 0\n",
    "        \n",
    "        for t in range(MAX_WORD_LEN + 10): # Max turns\n",
    "            valid_actions_mask = get_valid_actions_mask(guessed)\n",
    "            action_tensor = agent.select_action(state, valid_actions_mask)\n",
    "            action_char = INDEX_TO_CHAR[action_tensor.item()]\n",
    "            \n",
    "            (next_pattern, next_guessed, next_lives), reward, done = env.step(action_char)\n",
    "            \n",
    "            total_reward += reward\n",
    "            \n",
    "            # Get next state and mask\n",
    "            next_state = get_state_tensor(next_pattern, next_guessed, next_lives, agent.oracle)\n",
    "            next_valid_actions_mask = get_valid_actions_mask(next_guessed)\n",
    "            \n",
    "            # Store in buffer\n",
    "            agent.buffer.push(state, action_tensor, reward, next_state, done, next_valid_actions_mask)\n",
    "            \n",
    "            state = next_state\n",
    "            guessed = next_guessed\n",
    "            \n",
    "            agent.learn()\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        episode_rewards.append(total_reward)\n",
    "        \n",
    "        # --- Log Progress ---\n",
    "        if (i_episode + 1) % 100 == 0:\n",
    "            avg_reward = np.mean(episode_rewards[-100:])\n",
    "            print(f\"Episode {i_episode+1}/{NUM_EPISODES} | Avg Reward (last 100): {avg_reward:.2f}\")\n",
    "            \n",
    "        # Update the target network\n",
    "        if i_episode % TARGET_UPDATE == 0:\n",
    "            agent.target_net.load_state_dict(agent.policy_net.state_dict())\n",
    "\n",
    "    print(\"--- üèÅ Training Complete ---\")\n",
    "    \n",
    "    # Save the trained model\n",
    "    torch.save(agent.policy_net.state_dict(), \"dqn_hangman_model.pth\")\n",
    "    print(\"Model saved to dqn_hangman_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T08:35:57.106104Z",
     "iopub.status.busy": "2025-11-03T08:35:57.105622Z",
     "iopub.status.idle": "2025-11-03T08:36:09.165452Z",
     "shell.execute_reply": "2025-11-03T08:36:09.164837Z",
     "shell.execute_reply.started": "2025-11-03T08:35:57.106075Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Evaluation with Trained DQN Agent: 2000 games ---\n",
      "--- Evaluation Complete ---\n",
      "\n",
      "--- üìä Final Results (DQN Agent) ---\n",
      "**Final Score:** -55763.00\n",
      "------------------------------\n",
      "Total Games Played:     2000\n",
      "Total Games Won:        417 (20.85%)\n",
      "------------------------------\n",
      "Total Wrong Guesses:    11236 (Avg: 5.62 per game)\n",
      "Total Repeated Guesses: 0 (Avg: 0.00 per game)\n",
      "------------------------------\n",
      "Score from Wins:        + 417.00\n",
      "Penalty from Wrongs:    - 56180.00\n",
      "Penalty from Repeats:   - 0.00\n"
     ]
    }
   ],
   "source": [
    "# --- Final Evaluation ---\n",
    "# Load the trained model if needed (or just use 'agent' from previous cell)\n",
    "# policy_net = DQN().to(device)\n",
    "# policy_net.load_state_dict(torch.load(\"dqn_hangman_model.pth\"))\n",
    "# policy_net.eval()\n",
    "# agent.policy_net = policy_net\n",
    "\n",
    "# Use the 'agent' and 'env' from the training cell\n",
    "agent.policy_net.eval() # Set to evaluation mode (disables dropout, etc.)\n",
    "\n",
    "NUM_GAMES = 2000 # As specified in the PDF\n",
    "MAX_LIVES = 6\n",
    "\n",
    "total_games_won = 0\n",
    "total_wrong_guesses = 0\n",
    "total_repeated_guesses = 0\n",
    "\n",
    "print(f\"\\n--- Starting Evaluation with Trained DQN Agent: {NUM_GAMES} games ---\")\n",
    "\n",
    "for i in range(NUM_GAMES):\n",
    "    (pattern, guessed, lives) = env.reset()\n",
    "    done = False\n",
    "    \n",
    "    game_wrong_guesses = 0\n",
    "    game_repeated_guesses = 0\n",
    "    \n",
    "    while not done:\n",
    "        state = get_state_tensor(pattern, guessed, lives, agent.oracle)\n",
    "        valid_actions_mask = get_valid_actions_mask(guessed)\n",
    "        \n",
    "        # --- Pure Exploitation (No Epsilon) ---\n",
    "        with torch.no_grad():\n",
    "            q_values = agent.policy_net(state) # Shape [1, 26]\n",
    "            \n",
    "            # --- THIS LINE IS FIXED ---\n",
    "            # Apply the 1D mask to the 0-th batch item\n",
    "            q_values[0, ~valid_actions_mask] = -float('inf') \n",
    "            \n",
    "            action_tensor = q_values.max(1)[1]\n",
    "            \n",
    "        action_char = INDEX_TO_CHAR[action_tensor.item()]\n",
    "        \n",
    "        # --- Track penalties BEFORE stepping ---\n",
    "        if action_char in guessed:\n",
    "            game_repeated_guesses += 1\n",
    "        elif action_char not in env.secret_word:\n",
    "            game_wrong_guesses += 1\n",
    "        \n",
    "        (next_pattern, next_guessed, next_lives), reward, done = env.step(action_char)\n",
    "        pattern, guessed, lives = next_pattern, next_guessed, next_lives\n",
    "\n",
    "    if lives > 0: # Game was won\n",
    "        total_games_won += 1\n",
    "        \n",
    "    total_wrong_guesses += game_wrong_guesses\n",
    "    total_repeated_guesses += game_repeated_guesses\n",
    "\n",
    "print(\"--- Evaluation Complete ---\")\n",
    "\n",
    "# 1. Calculate Metrics\n",
    "success_rate = total_games_won / NUM_GAMES\n",
    "avg_wrong_guesses = total_wrong_guesses / NUM_GAMES\n",
    "avg_repeated_guesses = total_repeated_guesses / NUM_GAMES\n",
    "\n",
    "# 2. Calculate Final Score using the PDF formula\n",
    "score_from_wins = success_rate * 2000 \n",
    "penalty_from_wrongs = total_wrong_guesses * 5\n",
    "penalty_from_repeats = total_repeated_guesses * 2\n",
    "\n",
    "final_score = score_from_wins - penalty_from_wrongs - penalty_from_repeats\n",
    "\n",
    "# 3. Print Results\n",
    "print(\"\\n--- üìä Final Results (DQN Agent) ---\")\n",
    "print(f\"**Final Score:** {final_score:.2f}\")\n",
    "print(\"------------------------------\")\n",
    "print(f\"Total Games Played:     {NUM_GAMES}\")\n",
    "print(f\"Total Games Won:        {total_games_won} ({success_rate * 100:.2f}%)\")\n",
    "print(\"------------------------------\")\n",
    "print(f\"Total Wrong Guesses:    {total_wrong_guesses} (Avg: {avg_wrong_guesses:.2f} per game)\")\n",
    "print(f\"Total Repeated Guesses: {total_repeated_guesses} (Avg: {avg_repeated_guesses:.2f} per game)\")\n",
    "print(\"------------------------------\")\n",
    "print(f\"Score from Wins:        + {score_from_wins:.2f}\")\n",
    "print(f\"Penalty from Wrongs:    - {penalty_from_wrongs:.2f}\")\n",
    "print(f\"Penalty from Repeats:   - {penalty_from_repeats:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8636677,
     "sourceId": 13593116,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
