{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-03T08:29:08.023035Z",
     "iopub.status.busy": "2025-11-03T08:29:08.022854Z",
     "iopub.status.idle": "2025-11-03T08:29:08.027714Z",
     "shell.execute_reply": "2025-11-03T08:29:08.027024Z",
     "shell.execute_reply.started": "2025-11-03T08:29:08.023021Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported and alphabet defined.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import collections\n",
    "import os # For checking the file path\n",
    "\n",
    "# Define the alphabet and a mapping for easy indexing\n",
    "ALPHABET = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "CHAR_TO_INDEX = {char: i for i, char in enumerate(ALPHABET)}\n",
    "INDEX_TO_CHAR = {i: char for i, char in enumerate(ALPHABET)}\n",
    "\n",
    "print(\"Libraries imported and alphabet defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T08:29:10.148814Z",
     "iopub.status.busy": "2025-11-03T08:29:10.148142Z",
     "iopub.status.idle": "2025-11-03T08:29:10.189370Z",
     "shell.execute_reply": "2025-11-03T08:29:10.188761Z",
     "shell.execute_reply.started": "2025-11-03T08:29:10.148792Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus loaded successfully from corpus.txt.\n",
      "\n",
      "Word counts by length:\n",
      "  Length 1: 46 words\n",
      "  Length 2: 84 words\n",
      "  Length 3: 388 words\n",
      "  Length 4: 1169 words\n",
      "  Length 5: 2340 words\n",
      "  Length 6: 3755 words\n",
      "  Length 7: 5111 words\n",
      "  Length 8: 6348 words\n",
      "  Length 9: 6808 words\n",
      "  Length 10: 6465 words\n",
      "  Length 11: 5452 words\n",
      "  Length 12: 4292 words\n",
      "  Length 13: 3094 words\n",
      "  Length 14: 2019 words\n",
      "  Length 15: 1226 words\n",
      "  Length 16: 698 words\n",
      "  Length 17: 375 words\n",
      "  Length 18: 174 words\n",
      "  Length 19: 88 words\n",
      "  Length 20: 40 words\n",
      "  Length 21: 16 words\n",
      "  Length 22: 8 words\n",
      "  Length 23: 3 words\n",
      "  Length 24: 1 words\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import collections\n",
    "\n",
    "# Define the path to your local corpus file\n",
    "# Assumes 'corpus.txt' is in the same folder as your notebook\n",
    "LOCAL_CORPUS_PATH = \"corpus.txt\"\n",
    "\n",
    "def load_corpus(filename=LOCAL_CORPUS_PATH):\n",
    "    \"\"\"\n",
    "    Reads the corpus file from the specified local path\n",
    "    and groups words by length.\n",
    "    \"\"\"\n",
    "    words_by_length = collections.defaultdict(list)\n",
    "    \n",
    "    # Check if the file exists before trying to open it\n",
    "    if not os.path.exists(filename):\n",
    "        print(f\"--- ERROR ---\")\n",
    "        print(f\"File not found at: {filename}\")\n",
    "        print(\"Please make sure 'corpus.txt' is in the same folder as your notebook.\")\n",
    "        \n",
    "        # Helper to debug: list contents of the current directory\n",
    "        print(\"\\nListing contents of current directory ('.') ...\")\n",
    "        try:\n",
    "            print(os.listdir('.'))\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while listing the current directory: {e}\")\n",
    "        return None\n",
    "\n",
    "    # File exists, proceed to load\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            for word in f:\n",
    "                cleaned_word = word.strip().upper()\n",
    "                if cleaned_word: # Ensure it's not an empty line\n",
    "                    words_by_length[len(cleaned_word)].append(cleaned_word)\n",
    "        \n",
    "        print(f\"Corpus loaded successfully from {filename}.\")\n",
    "        print(\"\\nWord counts by length:\")\n",
    "        for length in sorted(words_by_length.keys()):\n",
    "            print(f\"  Length {length}: {len(words_by_length[length])} words\")\n",
    "        return words_by_length\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while reading the file: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load the corpus\n",
    "words_by_length = load_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T08:29:14.073512Z",
     "iopub.status.busy": "2025-11-03T08:29:14.072914Z",
     "iopub.status.idle": "2025-11-03T08:29:14.735865Z",
     "shell.execute_reply": "2025-11-03T08:29:14.735083Z",
     "shell.execute_reply.started": "2025-11-03T08:29:14.073487Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete. 24 (U, B, T) models trained.\n",
      "\n",
      "--- Trigram Model Sanity Check (5-letter words) ---\n",
      "  P(Letter at pos 2 = 'E' | ...pos 0 = 'T', pos 1 = 'H') = 0.0750\n"
     ]
    }
   ],
   "source": [
    "def train_hmm_models(words_by_length):\n",
    "    \"\"\"\n",
    "    Trains positional Unigram, Bigram, and Trigram models for each word length.\n",
    "    \"\"\"\n",
    "    hmm_models = {}\n",
    "    \n",
    "    for length, words in words_by_length.items():\n",
    "        if length == 0:\n",
    "            continue # Skip empty strings if any\n",
    "            \n",
    "        model = {}\n",
    "        \n",
    "        # --- 1. Unigram Model (Always possible for length >= 1) ---\n",
    "        unigram_counts = np.ones((length, 26))\n",
    "        for word in words:\n",
    "            try:\n",
    "                for pos, char in enumerate(word):\n",
    "                    unigram_counts[pos, CHAR_TO_INDEX[char]] += 1\n",
    "            except KeyError:\n",
    "                continue\n",
    "        model['unigram'] = unigram_counts / unigram_counts.sum(axis=1, keepdims=True)\n",
    "\n",
    "        # --- 2. Bigram Model (Only possible for length >= 2) ---\n",
    "        if length >= 2:\n",
    "            bigram_counts = np.ones((length - 1, 26, 26))\n",
    "            for word in words:\n",
    "                try:\n",
    "                    for pos in range(length - 1):\n",
    "                        prev_char_idx = CHAR_TO_INDEX[word[pos]]\n",
    "                        curr_char_idx = CHAR_TO_INDEX[word[pos + 1]]\n",
    "                        bigram_counts[pos, prev_char_idx, curr_char_idx] += 1\n",
    "                except KeyError:\n",
    "                    continue\n",
    "            model['bigram'] = bigram_counts / bigram_counts.sum(axis=2, keepdims=True)\n",
    "\n",
    "        # --- 3. Trigram Model (Only possible for length >= 3) ---\n",
    "        if length >= 3:\n",
    "            trigram_counts = np.ones((length - 2, 26, 26, 26))\n",
    "            for word in words:\n",
    "                try:\n",
    "                    for pos in range(length - 2):\n",
    "                        prev_prev_char_idx = CHAR_TO_INDEX[word[pos]]\n",
    "                        prev_char_idx = CHAR_TO_INDEX[word[pos + 1]]\n",
    "                        curr_char_idx = CHAR_TO_INDEX[word[pos + 2]]\n",
    "                        trigram_counts[pos, prev_prev_char_idx, prev_char_idx, curr_char_idx] += 1\n",
    "                except KeyError:\n",
    "                    continue\n",
    "            model['trigram'] = trigram_counts / trigram_counts.sum(axis=3, keepdims=True)\n",
    "        \n",
    "        # Store the trained models\n",
    "        hmm_models[length] = model\n",
    "        \n",
    "    print(f\"Training complete. {len(hmm_models)} (U, B, T) models trained.\")\n",
    "    return hmm_models\n",
    "\n",
    "# --- Re-train the models ---\n",
    "hmm_models = train_hmm_models(words_by_length)\n",
    "\n",
    "# --- Example: Check 'TH' -> 'E' transition for 5-letter words ---\n",
    "if 5 in hmm_models:\n",
    "    t_idx = CHAR_TO_INDEX['T']\n",
    "    h_idx = CHAR_TO_INDEX['H']\n",
    "    e_idx = CHAR_TO_INDEX['E']\n",
    "    \n",
    "    # Get P(Letter_2 | Letter_0='T', Letter_1='H')\n",
    "    if 'trigram' in hmm_models[5]:\n",
    "        prob_th_e = hmm_models[5]['trigram'][0, t_idx, h_idx, e_idx]\n",
    "        print(\"\\n--- Trigram Model Sanity Check (5-letter words) ---\")\n",
    "        print(f\"  P(Letter at pos 2 = 'E' | ...pos 0 = 'T', pos 1 = 'H') = {prob_th_e:.4f}\")\n",
    "    else:\n",
    "        print(\"Trigram model for length 5 not available (this shouldn't happen).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T08:29:17.818945Z",
     "iopub.status.busy": "2025-11-03T08:29:17.818712Z",
     "iopub.status.idle": "2025-11-03T08:29:17.830023Z",
     "shell.execute_reply": "2025-11-03T08:29:17.829118Z",
     "shell.execute_reply.started": "2025-11-03T08:29:17.818928Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HMMOracle (Trigram w/ Backoff) initialized.\n"
     ]
    }
   ],
   "source": [
    "class HMMOracle:\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        print(\"HMMOracle (Trigram w/ Backoff) initialized.\")\n",
    "\n",
    "    def _get_prob_with_backoff(self, model, pos, pattern, char_index):\n",
    "        \"\"\"\n",
    "        Gets the probability of a character at a specific position,\n",
    "        using the best available n-gram model (Trigram -> Bigram -> Unigram).\n",
    "        \"\"\"\n",
    "        \n",
    "        # --- Try Trigram ---\n",
    "        # P(char | char_at_pos-2, char_at_pos-1)\n",
    "        if pos >= 2 and pattern[pos-2] != '_' and pattern[pos-1] != '_':\n",
    "            prev_prev_idx = CHAR_TO_INDEX[pattern[pos-2]]\n",
    "            prev_idx = CHAR_TO_INDEX[pattern[pos-1]]\n",
    "            # trigram_probs[pos-2, char_{i-2}, char_{i-1}, char_i]\n",
    "            return model['trigram'][pos-2, prev_prev_idx, prev_idx, char_index]\n",
    "            \n",
    "        # --- Try Bigram ---\n",
    "        # P(char | char_at_pos-1)\n",
    "        if pos >= 1 and pattern[pos-1] != '_':\n",
    "            prev_idx = CHAR_TO_INDEX[pattern[pos-1]]\n",
    "            # bigram_probs[pos-1, char_{i-1}, char_i]\n",
    "            return model['bigram'][pos-1, prev_idx, char_index]\n",
    "            \n",
    "        # --- Fallback to Unigram ---\n",
    "        # P(char_i)\n",
    "        return model['unigram'][pos, char_index]\n",
    "        \n",
    "\n",
    "    def get_letter_probabilities(self, pattern, guessed_letters):\n",
    "        \"\"\"\n",
    "        Estimates the probability of each remaining letter appearing\n",
    "        in one of the blank spots, using trigram backoff logic.\n",
    "        \"\"\"\n",
    "        word_length = len(pattern)\n",
    "        \n",
    "        if word_length not in self.models:\n",
    "            # Fallback for models we couldn't train (e.g., length 1)\n",
    "            unguessed = [c for c in ALPHABET if c not in guessed_letters]\n",
    "            if not unguessed: return {}\n",
    "            prob = 1.0 / len(unguessed)\n",
    "            return {char: prob for char in unguessed}\n",
    "            \n",
    "        model = self.models[word_length]\n",
    "        \n",
    "        blank_indices = [i for i, char in enumerate(pattern) if char == '_']\n",
    "        unguessed_chars = [c for c in ALPHABET if c not in guessed_letters]\n",
    "        \n",
    "        if not blank_indices or not unguessed_chars:\n",
    "            return {}\n",
    "            \n",
    "        final_scores = {char: 0.0 for char in unguessed_chars}\n",
    "        \n",
    "        # 3. Iterate over each blank and score each candidate letter\n",
    "        for blank_pos in blank_indices:\n",
    "            for char in unguessed_chars:\n",
    "                char_index = CHAR_TO_INDEX[char]\n",
    "                \n",
    "                # --- P(Letter | Left_Neighbors) ---\n",
    "                # Get the probability of this char given its left context\n",
    "                left_prob = self._get_prob_with_backoff(model, blank_pos, pattern, char_index)\n",
    "                \n",
    "                # --- P(Right_Neighbors | Letter) ---\n",
    "                # Now, find how well this char \"predicts\" its right-side context\n",
    "                right_prob = 1.0\n",
    "                \n",
    "                # Check for known letter at pos+1\n",
    "                if blank_pos + 1 < word_length and pattern[blank_pos+1] != '_':\n",
    "                    next_idx = CHAR_TO_INDEX[pattern[blank_pos+1]]\n",
    "                    # P(char_at_pos+1 | char_at_pos)\n",
    "                    right_prob *= model['bigram'][blank_pos, char_index, next_idx]\n",
    "                \n",
    "                # Check for known letter at pos+2\n",
    "                if blank_pos + 2 < word_length and pattern[blank_pos+1] != '_' and pattern[blank_pos+2] != '_':\n",
    "                    next_idx = CHAR_TO_INDEX[pattern[blank_pos+1]]\n",
    "                    next_next_idx = CHAR_TO_INDEX[pattern[blank_pos+2]]\n",
    "                    # P(char_at_pos+2 | char_at_pos, char_at_pos+1)\n",
    "                    right_prob *= model['trigram'][blank_pos, char_index, next_idx, next_next_idx]\n",
    "                \n",
    "                # This score represents how well this char \"fits\" in this blank\n",
    "                prob_at_this_pos = left_prob * right_prob\n",
    "                final_scores[char] += prob_at_this_pos\n",
    "\n",
    "        # 4. Normalize scores to create a probability distribution\n",
    "        total_score = sum(final_scores.values())\n",
    "        \n",
    "        if total_score == 0.0:\n",
    "            # Fallback: No letter fits, return uniform prob\n",
    "            prob = 1.0 / len(unguessed_chars)\n",
    "            return {char: prob for char in unguessed_chars}\n",
    "            \n",
    "        normalized_probs = {\n",
    "            char: score / total_score\n",
    "            for char, score in final_scores.items()\n",
    "        }\n",
    "        \n",
    "        return normalized_probs\n",
    "\n",
    "# --- Initialize the new oracle ---\n",
    "if 'hmm_models' in locals():\n",
    "    oracle = HMMOracle(hmm_models)\n",
    "else:\n",
    "    print(\"Error: 'hmm_models' not initialized. Please re-run Cell 3.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T08:29:20.893831Z",
     "iopub.status.busy": "2025-11-03T08:29:20.893310Z",
     "iopub.status.idle": "2025-11-03T08:29:20.901009Z",
     "shell.execute_reply": "2025-11-03T08:29:20.900448Z",
     "shell.execute_reply.started": "2025-11-03T08:29:20.893811Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Probs for 'S____' (guessed: {'S'}) ---\n",
      "  P(E): 0.1110\n",
      "  P(A): 0.1020\n",
      "  P(T): 0.0788\n",
      "  P(I): 0.0689\n",
      "  P(O): 0.0680\n",
      "  P(N): 0.0642\n",
      "  P(L): 0.0616\n",
      "  P(R): 0.0597\n",
      "  P(H): 0.0460\n",
      "  P(C): 0.0452\n",
      "\n",
      "--- Probs for '_PPLE' (guessed: {'E', 'P', 'L'}) ---\n",
      "  P(S): 0.3186\n",
      "  P(U): 0.1231\n",
      "  P(A): 0.1220\n",
      "  P(M): 0.0451\n",
      "  P(H): 0.0417\n",
      "\n",
      "--- Probs for '__A_I_G' (guessed: {'A', 'G', 'I'}) ---\n",
      "  P(N): 0.1331\n",
      "  P(S): 0.0988\n",
      "  P(C): 0.0816\n",
      "  P(P): 0.0694\n",
      "  P(R): 0.0683\n",
      "  P(T): 0.0681\n",
      "  P(B): 0.0622\n",
      "  P(L): 0.0589\n",
      "  P(M): 0.0515\n",
      "  P(D): 0.0482\n"
     ]
    }
   ],
   "source": [
    "# --- Example 1: A common 5-letter word start ---\n",
    "pattern1 = \"S____\"\n",
    "guessed1 = {'S'}\n",
    "probs1 = oracle.get_letter_probabilities(pattern1, guessed1)\n",
    "\n",
    "print(f\"--- Probs for '{pattern1}' (guessed: {guessed1}) ---\")\n",
    "# Sort by probability, descending\n",
    "for char, prob in sorted(probs1.items(), key=lambda item: item[1], reverse=True)[:10]:\n",
    "    print(f\"  P({char}): {prob:.4f}\")\n",
    "\n",
    "\n",
    "# --- Example 2: The 'APPLE' example from the prompt ---\n",
    "pattern2 = \"_PPLE\"\n",
    "guessed2 = {'P', 'L', 'E'}\n",
    "probs2 = oracle.get_letter_probabilities(pattern2, guessed2)\n",
    "\n",
    "print(f\"\\n--- Probs for '{pattern2}' (guessed: {guessed2}) ---\")\n",
    "for char, prob in sorted(probs2.items(), key=lambda item: item[1], reverse=True)[:5]:\n",
    "    print(f\"  P({char}): {prob:.4f}\")\n",
    "\n",
    "    \n",
    "# --- Example 3: More complex pattern ---\n",
    "pattern3 = \"__A_I_G\"\n",
    "guessed3 = {'A', 'I', 'G'}\n",
    "probs3 = oracle.get_letter_probabilities(pattern3, guessed3)\n",
    "\n",
    "print(f\"\\n--- Probs for '{pattern3}' (guessed: {guessed3}) ---\")\n",
    "for char, prob in sorted(probs3.items(), key=lambda item: item[1], reverse=True)[:10]:\n",
    "    print(f\"  P({char}): {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T08:29:28.548860Z",
     "iopub.status.busy": "2025-11-03T08:29:28.548209Z",
     "iopub.status.idle": "2025-11-03T08:29:30.966560Z",
     "shell.execute_reply": "2025-11-03T08:29:30.965879Z",
     "shell.execute_reply.started": "2025-11-03T08:29:28.548838Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loaded successfully from test.txt.\n",
      "Found 2000 test words.\n",
      "\n",
      "--- Starting Evaluation: Playing 2000 games ---\n",
      "  ... processed 200 / 2000 iterations\n",
      "  ... processed 400 / 2000 iterations\n",
      "  ... processed 600 / 2000 iterations\n",
      "  ... processed 800 / 2000 iterations\n",
      "  ... processed 1000 / 2000 iterations\n",
      "  ... processed 1200 / 2000 iterations\n",
      "  ... processed 1400 / 2000 iterations\n",
      "  ... processed 1600 / 2000 iterations\n",
      "  ... processed 1800 / 2000 iterations\n",
      "  ... processed 2000 / 2000 iterations\n",
      "--- Evaluation Complete ---\n",
      "\n",
      "--- üìä Final Results ---\n",
      "**Final Score (scaled to 2000 games):** -48934.00\n",
      "------------------------------\n",
      "Total Games Played:     2000\n",
      "Total Games Won:        781 (39.05%)\n",
      "------------------------------\n",
      "Total Wrong Guesses:    9943 (Avg: 4.97 per game)\n",
      "Total Repeated Guesses: 0 (Avg: 0.00 per game)\n",
      "------------------------------\n",
      "Scaled Score from Wins:   + 781.00\n",
      "Scaled Penalty (Wrongs):  - 49715.00\n",
      "Scaled Penalty (Repeats): - 0.00\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import collections # Added this import, as it was missing from your first snippet\n",
    "\n",
    "# --- Assume 'oracle' is defined elsewhere ---\n",
    "# For this code to run, you must have your HMMOracle class defined \n",
    "# and an instance created, e.g.:\n",
    "# oracle = HMMOracle(words_by_length) \n",
    "#\n",
    "# --- Assume 'words_by_length' is loaded from your first script ---\n",
    "# Example:\n",
    "# words_by_length = load_corpus() # From your previous code block\n",
    "\n",
    "# Define the path to your local test set file\n",
    "# Assumes 'test.txt' is in the same folder as your notebook\n",
    "LOCAL_TEST_SET_PATH = \"test.txt\"\n",
    "\n",
    "def load_test_set(filename=LOCAL_TEST_SET_PATH):\n",
    "    \"\"\"\n",
    "    Loads the test set words from the specified local path.\n",
    "    \"\"\"\n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(filename):\n",
    "        print(f\"--- ERROR ---\")\n",
    "        print(f\"Test set file not found at: {filename}\")\n",
    "        print(\"Please make sure 'test.txt' is in the same folder as your notebook.\")\n",
    "        \n",
    "        # Helper to debug: list contents of the current directory\n",
    "        print(\"\\nListing contents of current directory ('.') ...\")\n",
    "        try:\n",
    "            print(os.listdir('.'))\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while listing the current directory: {e}\")\n",
    "        return None\n",
    "\n",
    "    # File exists, proceed to load\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            # Read words, strip whitespace, convert to upper, and ignore empty lines\n",
    "            test_words = [word.strip().upper() for word in f if word.strip()]\n",
    "        \n",
    "        print(f\"Test set loaded successfully from {filename}.\")\n",
    "        print(f\"Found {len(test_words)} test words.\")\n",
    "        return test_words\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while reading the test file: {e}\")\n",
    "        return None\n",
    "\n",
    "def play_game(secret_word, oracle, max_lives=6):\n",
    "    \"\"\"\n",
    "    Simulates a single game of Hangman using a greedy agent\n",
    "    that trusts the HMMOracle.\n",
    "    \"\"\"\n",
    "    word_length = len(secret_word)\n",
    "    pattern = \"_\" * word_length\n",
    "    guessed_letters = set()\n",
    "    \n",
    "    wrong_guesses = 0\n",
    "    repeated_guesses = 0 # Will be 0 with our current oracle\n",
    "    lives = max_lives\n",
    "    \n",
    "    while lives > 0 and \"_\" in pattern:\n",
    "        # 1. Get probabilities from the HMM oracle\n",
    "        probs = oracle.get_letter_probabilities(pattern, guessed_letters)\n",
    "        \n",
    "        # 2. Check for failure case (e.g., oracle returns nothing)\n",
    "        if not probs:\n",
    "            break # Game is lost\n",
    "            \n",
    "        # 3. Greedy Agent: Pick the best letter\n",
    "        guess = max(probs, key=probs.get)\n",
    "        \n",
    "        # Note: Our HMMOracle already filters for guessed_letters,\n",
    "        # so repeated_guesses will be 0. The RL agent, however,\n",
    "        # might make this mistake, which is why it's in the formula.\n",
    "        \n",
    "        # 4. Update game state\n",
    "        guessed_letters.add(guess)\n",
    "        \n",
    "        if guess in secret_word:\n",
    "            # Correct guess: update pattern\n",
    "            new_pattern = list(pattern)\n",
    "            for i in range(word_length):\n",
    "                if secret_word[i] == guess:\n",
    "                    new_pattern[i] = guess\n",
    "            pattern = \"\".join(new_pattern)\n",
    "        else:\n",
    "            # Wrong guess\n",
    "            wrong_guesses += 1\n",
    "            lives -= 1\n",
    "            \n",
    "    # 5. Return game results\n",
    "    game_won = \"_\" not in pattern\n",
    "    return game_won, wrong_guesses, repeated_guesses\n",
    "\n",
    "# --- Main Evaluation Loop ---\n",
    "\n",
    "# Load the test words\n",
    "test_words = load_test_set()\n",
    "\n",
    "# Check if both the test set AND the oracle (from your other script) are loaded\n",
    "if test_words and 'oracle' in locals() and oracle:\n",
    "    NUM_GAMES = 2000 # As specified in the PDF \n",
    "    MAX_LIVES = 6      # As specified in the PDF \n",
    "    \n",
    "    total_games_won = 0\n",
    "    total_wrong_guesses = 0\n",
    "    total_repeated_guesses = 0\n",
    "    \n",
    "    print(f\"\\n--- Starting Evaluation: Playing {NUM_GAMES} games ---\")\n",
    "    \n",
    "    # Ensure we have words to play with\n",
    "    if not test_words:\n",
    "        print(\"Cannot run evaluation: test_words list is empty.\")\n",
    "    else:\n",
    "        test_set_size = len(test_words)\n",
    "        \n",
    "        games_played = 0 # Track actual games played if some are skipped\n",
    "        \n",
    "        for i in range(NUM_GAMES):\n",
    "            # Pick a word.\n",
    "            # We use random.choice to get a good sample\n",
    "            secret_word = random.choice(test_words)\n",
    "            \n",
    "            # Ensure the oracle has a model for this word length\n",
    "            if len(secret_word) not in oracle.models:\n",
    "                # print(f\"Skipping word '{secret_word}': No model for length {len(secret_word)}\")\n",
    "                continue # Skip this game\n",
    "\n",
    "            won, wrongs, repeats = play_game(secret_word, oracle, MAX_LIVES)\n",
    "            \n",
    "            games_played += 1 # Only increment if a game was actually played\n",
    "            \n",
    "            if won:\n",
    "                total_games_won += 1\n",
    "            total_wrong_guesses += wrongs\n",
    "            total_repeated_guesses += repeats\n",
    "            \n",
    "            if (i + 1) % 200 == 0:\n",
    "                print(f\"  ... processed {i + 1} / {NUM_GAMES} iterations\")\n",
    "\n",
    "        print(\"--- Evaluation Complete ---\")\n",
    "\n",
    "        if games_played == 0:\n",
    "            print(\"\\n--- ‚ö†Ô∏è No games were played! ---\")\n",
    "            print(\"This usually means the test set words have lengths\")\n",
    "            print(\"that were not present in your training corpus (words_by_length).\")\n",
    "            print(\"Please check your corpus.txt and test.txt files.\")\n",
    "        else:\n",
    "            # 1. Calculate Metrics\n",
    "            success_rate = total_games_won / games_played\n",
    "            avg_wrong_guesses = total_wrong_guesses / games_played\n",
    "            avg_repeated_guesses = total_repeated_guesses / games_played\n",
    "            \n",
    "            # 2. Calculate Final Score using the formula \n",
    "            # Final Score = (Success Rate * 2000) - (Total Wrong Guesses * 5) - (Total Repeated Guesses * 2)\n",
    "            \n",
    "            # We scale the score to 2000 games, even if some were skipped\n",
    "            # This assumes skipped games would have performed at the average rate\n",
    "            \n",
    "            # Calculate score based on games played\n",
    "            score_from_wins = (total_games_won / games_played) * 2000 \n",
    "            total_wrong_for_2000 = (total_wrong_guesses / games_played) * 2000\n",
    "            total_repeats_for_2000 = (total_repeated_guesses / games_played) * 2000\n",
    "            \n",
    "            penalty_from_wrongs = total_wrong_for_2000 * 5\n",
    "            penalty_from_repeats = total_repeats_for_2000 * 2\n",
    "            \n",
    "            final_score = score_from_wins - penalty_from_wrongs - penalty_from_repeats\n",
    "            \n",
    "            # 3. Print Results\n",
    "            print(\"\\n--- üìä Final Results ---\")\n",
    "            print(f\"**Final Score (scaled to 2000 games):** {final_score:.2f}\")\n",
    "            print(\"------------------------------\")\n",
    "            print(f\"Total Games Played:     {games_played}\")\n",
    "            print(f\"Total Games Won:        {total_games_won} ({success_rate * 100:.2f}%)\")\n",
    "            print(\"------------------------------\")\n",
    "            print(f\"Total Wrong Guesses:    {total_wrong_guesses} (Avg: {avg_wrong_guesses:.2f} per game)\")\n",
    "            print(f\"Total Repeated Guesses: {total_repeated_guesses} (Avg: {avg_repeated_guesses:.2f} per game)\")\n",
    "            print(\"------------------------------\")\n",
    "            print(f\"Scaled Score from Wins:   + {score_from_wins:.2f}\")\n",
    "            print(f\"Scaled Penalty (Wrongs):  - {penalty_from_wrongs:.2f}\")\n",
    "            print(f\"Scaled Penalty (Repeats): - {penalty_from_repeats:.2f}\")\n",
    "            \n",
    "else:\n",
    "    print(\"\\nEvaluation not run. Check the following:\")\n",
    "    if not test_words:\n",
    "        print(\" - 'test_words' could not be loaded.\")\n",
    "    if 'oracle' not in locals() or not oracle:\n",
    "        print(\" - 'oracle' is not initialized. Make sure you have run the HMMOracle class definition and created an instance.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T08:29:42.974864Z",
     "iopub.status.busy": "2025-11-03T08:29:42.974345Z",
     "iopub.status.idle": "2025-11-03T08:29:43.003570Z",
     "shell.execute_reply": "2025-11-03T08:29:43.002799Z",
     "shell.execute_reply.started": "2025-11-03T08:29:42.974841Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 49398 unique words from corpus.txt\n",
      "Loaded 2000 unique words from test.txt\n",
      "\n",
      "--- üìä Diagnostic Results ---\n",
      "Total Test Words:     2000\n",
      "Total Corpus Words:   49398\n",
      "Words in BOTH files:  0\n",
      "Overlap Percentage:   0.00%\n",
      "\n",
      "**CRITICAL FINDING:** Your test set has 0% overlap with your training corpus.\n",
      "This means the corpus filtering logic will *never* be used during evaluation.\n",
      "The score you are seeing is purely from your bigram fallback model.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# --- Load Corpus Words into a Set ---\n",
    "LOCAL_CORPUS_PATH = \"corpus.txt\" # Changed path\n",
    "corpus_words = set()\n",
    "try:\n",
    "    with open(LOCAL_CORPUS_PATH, 'r') as f:\n",
    "        for word in f:\n",
    "            corpus_words.add(word.strip().upper())\n",
    "    print(f\"Loaded {len(corpus_words)} unique words from {LOCAL_CORPUS_PATH}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: '{LOCAL_CORPUS_PATH}' not found.\")\n",
    "    print(\"Please make sure it's in the same folder as your notebook.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading corpus: {e}\")\n",
    "\n",
    "# --- Load Test Words into a Set ---\n",
    "LOCAL_TEST_SET_PATH = \"test.txt\" # Changed path\n",
    "test_words = set()\n",
    "try:\n",
    "    with open(LOCAL_TEST_SET_PATH, 'r') as f:\n",
    "        for word in f:\n",
    "            test_words.add(word.strip().upper())\n",
    "    print(f\"Loaded {len(test_words)} unique words from {LOCAL_TEST_SET_PATH}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: '{LOCAL_TEST_SET_PATH}' not found.\")\n",
    "    print(\"Please make sure it's in the same folder as your notebook.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading test set: {e}\")\n",
    "\n",
    "# --- Calculate and Print Overlap ---\n",
    "if test_words and corpus_words:\n",
    "    overlap = test_words.intersection(corpus_words)\n",
    "    overlap_percentage = (len(overlap) / len(test_words)) * 100\n",
    "    \n",
    "    print(\"\\n--- üìä Diagnostic Results ---\")\n",
    "    print(f\"Total Test Words:     {len(test_words)}\")\n",
    "    print(f\"Total Corpus Words:   {len(corpus_words)}\")\n",
    "    print(f\"Words in BOTH files:  {len(overlap)}\")\n",
    "    print(f\"Overlap Percentage:   {overlap_percentage:.2f}%\")\n",
    "    \n",
    "    if overlap_percentage == 0.0:\n",
    "        print(\"\\n**CRITICAL FINDING:** Your test set has 0% overlap with your training corpus.\")\n",
    "        print(\"This means the corpus filtering logic will *never* be used during evaluation.\")\n",
    "        print(\"The score you are seeing is purely from your bigram fallback model.\")\n",
    "    elif overlap_percentage < 100.0:\n",
    "        print(f\"\\n**FINDING:** Only {overlap_percentage:.2f}% of your test words are in the corpus.\")\n",
    "        print(\"This means your filter is only working for a fraction of the games.\")\n",
    "    else:\n",
    "        print(\"\\n**FINDING:** 100% of test words are in the corpus.\")\n",
    "        print(\"This is good! It means the problem is likely a logic bug in your oracle.\")\n",
    "else:\n",
    "    print(\"\\nCould not calculate overlap. One or both files failed to load.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T08:29:48.079022Z",
     "iopub.status.busy": "2025-11-03T08:29:48.078297Z",
     "iopub.status.idle": "2025-11-03T08:29:54.134398Z",
     "shell.execute_reply": "2025-11-03T08:29:54.133716Z",
     "shell.execute_reply.started": "2025-11-03T08:29:48.078999Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "import collections\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Check if a GPU is available for training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T08:29:58.544352Z",
     "iopub.status.busy": "2025-11-03T08:29:58.543577Z",
     "iopub.status.idle": "2025-11-03T08:29:58.553362Z",
     "shell.execute_reply": "2025-11-03T08:29:58.552633Z",
     "shell.execute_reply.started": "2025-11-03T08:29:58.544327Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HangmanEnv will use the 2000 words from test_set.txt.\n"
     ]
    }
   ],
   "source": [
    "# Make sure 'test_words' is loaded from Cell 6\n",
    "if 'test_words' not in locals() or test_words is None:\n",
    "    print(\"CRITICAL ERROR: 'test_words' is not defined.\")\n",
    "    print(\"Please re-run Cell 6 to load the test set before this cell.\")\n",
    "else:\n",
    "    print(f\"HangmanEnv will use the {len(test_words)} words from test_set.txt.\")\n",
    "\n",
    "class HangmanEnv:\n",
    "    def __init__(self, word_list, max_lives=6):\n",
    "        self.word_list = [word for word in word_list if word] # Ensure no empty strings\n",
    "        self.max_lives = max_lives\n",
    "        self.secret_word = \"\"\n",
    "        self.pattern = \"\"\n",
    "        self.guessed_letters = set()\n",
    "        self.lives_left = 0\n",
    "        \n",
    "    def reset(self):\n",
    "        \"\"\"Starts a new game and returns the initial state.\"\"\"\n",
    "        self.secret_word = random.choice(self.word_list).upper()\n",
    "        self.pattern = \"_\" * len(self.secret_word)\n",
    "        self.guessed_letters = set()\n",
    "        self.lives_left = self.max_lives\n",
    "        \n",
    "        return (self.pattern, self.guessed_letters, self.lives_left)\n",
    "\n",
    "    def step(self, action_char):\n",
    "        \"\"\"\n",
    "        Takes an action (a letter) and returns:\n",
    "        (next_pattern, next_guessed, next_lives), reward, done\n",
    "        \"\"\"\n",
    "        \n",
    "        # --- 1. Check for invalid game state ---\n",
    "        if self.lives_left == 0 or \"_\" not in self.pattern:\n",
    "            return (self.pattern, self.guessed_letters, self.lives_left), 0, True # Game is already over\n",
    "\n",
    "        # --- 2. Define Rewards ---\n",
    "        REWARD_WIN = 200\n",
    "        REWARD_LOSE = -200\n",
    "        REWARD_CORRECT = 5\n",
    "        REWARD_WRONG = -10\n",
    "        REWARD_REPEAT = -2 ## this was orginally -5, but that makes no sense\n",
    "        \n",
    "        # --- 3. Process Action ---\n",
    "        done = False\n",
    "        reward = 0\n",
    "        \n",
    "        if action_char in self.guessed_letters:\n",
    "            # --- 3a. Repeated Guess ---\n",
    "            reward = REWARD_REPEAT\n",
    "        \n",
    "        else:\n",
    "            self.guessed_letters.add(action_char)\n",
    "            \n",
    "            if action_char in self.secret_word:\n",
    "                # --- 3b. Correct Guess ---\n",
    "                new_pattern = list(self.pattern)\n",
    "                for i, char in enumerate(self.secret_word):\n",
    "                    if char == action_char:\n",
    "                        new_pattern[i] = action_char\n",
    "                self.pattern = \"\".join(new_pattern)\n",
    "                \n",
    "                if \"_\" not in self.pattern:\n",
    "                    # Game Won!\n",
    "                    reward = REWARD_WIN\n",
    "                    done = True\n",
    "                else:\n",
    "                    # Correct, but not won yet\n",
    "                    reward = REWARD_CORRECT\n",
    "            \n",
    "            else:\n",
    "                # --- 3c. Wrong Guess ---\n",
    "                self.lives_left -= 1\n",
    "                if self.lives_left == 0:\n",
    "                    # Game Lost!\n",
    "                    reward = REWARD_LOSE\n",
    "                    done = True\n",
    "                else:\n",
    "                    # Wrong, but not lost yet\n",
    "                    reward = REWARD_WRONG\n",
    "\n",
    "        return (self.pattern, self.guessed_letters, self.lives_left), reward, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T08:30:59.490142Z",
     "iopub.status.busy": "2025-11-03T08:30:59.489492Z",
     "iopub.status.idle": "2025-11-03T08:30:59.497849Z",
     "shell.execute_reply": "2025-11-03T08:30:59.497082Z",
     "shell.execute_reply.started": "2025-11-03T08:30:59.490122Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Hyperparameters ---\n",
    "MAX_WORD_LEN = 30 # (Still needed by env, but not by agent)\n",
    "CHAR_TO_INT = {char: i+1 for i, char in enumerate(ALPHABET)}\n",
    "CHAR_TO_INT['_'] = 0\n",
    "\n",
    "# --- Replay Buffer ---\n",
    "Experience = collections.namedtuple('Experience', \n",
    "                                    ('state', 'action', 'reward', 'next_state', 'done', 'valid_actions'))\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = collections.deque(maxlen=capacity)\n",
    "    \n",
    "    def push(self, *args):\n",
    "        self.buffer.append(Experience(*args))\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.buffer, batch_size)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "# --- State Processor ---\n",
    "def get_state_tensor(pattern, guessed_letters, lives, oracle):\n",
    "    \"\"\"\n",
    "    Converts the raw game state into a dictionary of tensors for the network.\n",
    "    This version is SIMPLIFIED and does NOT include the pattern embedding.\n",
    "    \"\"\"\n",
    "    # 1. Guessed Vector\n",
    "    guessed_vec = [1.0 if char in guessed_letters else 0.0 for char in ALPHABET]\n",
    "    guessed_tensor = torch.tensor(guessed_vec, dtype=torch.float, device=device).unsqueeze(0) # Shape: [1, 26]\n",
    "    \n",
    "    # 2. Lives\n",
    "    lives_tensor = torch.tensor([[lives / 6.0]], dtype=torch.float, device=device) # Shape: [1, 1]\n",
    "    \n",
    "    # 3. HMM Probabilities\n",
    "    hmm_probs = oracle.get_letter_probabilities(pattern, guessed_letters)\n",
    "    hmm_vec = [hmm_probs.get(char, 0.0) for char in ALPHABET]\n",
    "    hmm_tensor = torch.tensor(hmm_vec, dtype=torch.float, device=device).unsqueeze(0) # Shape: [1, 26]\n",
    "\n",
    "    return {\n",
    "        \"guessed\": guessed_tensor,\n",
    "        \"lives\": lives_tensor,\n",
    "        \"hmm\": hmm_tensor\n",
    "    }\n",
    "\n",
    "def get_valid_actions_mask(guessed_letters):\n",
    "    \"\"\"\n",
    "    Returns a 26-element boolean tensor.\n",
    "    True if the action is VALID (not guessed), False if INVALID (guessed).\n",
    "    \"\"\"\n",
    "    mask = [True if char not in guessed_letters else False for char in ALPHABET]\n",
    "    return torch.tensor(mask, dtype=torch.bool, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T08:31:03.828874Z",
     "iopub.status.busy": "2025-11-03T08:31:03.828222Z",
     "iopub.status.idle": "2025-11-03T08:31:03.833814Z",
     "shell.execute_reply": "2025-11-03T08:31:03.833222Z",
     "shell.execute_reply.started": "2025-11-03T08:31:03.828850Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, vocab_size=27, embedding_dim=16, max_len=MAX_WORD_LEN):\n",
    "        super(DQN, self).__init__()\n",
    "        \n",
    "        # --- Total feature size ---\n",
    "        # guessed_vec (26) + lives (1) + hmm_vec (26)\n",
    "        total_feature_size = 26 + 1 + 26\n",
    "        \n",
    "        # --- Fully Connected Layers ---\n",
    "        self.fc1 = nn.Linear(total_feature_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        # Output layer: 26 Q-values, one for each letter\n",
    "        self.fc3 = nn.Linear(128, 26) \n",
    "\n",
    "    def forward(self, state):\n",
    "        \n",
    "        # 1. Concatenate all features\n",
    "        x = torch.cat([\n",
    "            state[\"guessed\"],\n",
    "            state[\"lives\"],\n",
    "            state[\"hmm\"]\n",
    "        ], dim=1) # Concatenate along the feature dimension\n",
    "        \n",
    "        # 2. Pass through MLP\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # 3. Output Q-values\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T08:31:06.478797Z",
     "iopub.status.busy": "2025-11-03T08:31:06.478315Z",
     "iopub.status.idle": "2025-11-03T08:31:06.491645Z",
     "shell.execute_reply": "2025-11-03T08:31:06.490894Z",
     "shell.execute_reply.started": "2025-11-03T08:31:06.478774Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- More Hyperparameters ---\n",
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.99       # Discount factor\n",
    "EPS_START = 0.9     # Epsilon-greedy exploration start\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 2000    # How fast epsilon decays\n",
    "TARGET_UPDATE = 10  # How often to update the target network (in episodes)\n",
    "BUFFER_CAPACITY = 10000\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self, oracle):\n",
    "        self.policy_net = DQN().to(device)\n",
    "        self.target_net = DQN().to(device)\n",
    "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
    "        self.target_net.eval() # Target net is only for evaluation\n",
    "        \n",
    "        self.optimizer = optim.Adam(self.policy_net.parameters(), lr=LEARNING_RATE)\n",
    "        self.buffer = ReplayBuffer(BUFFER_CAPACITY)\n",
    "        self.oracle = oracle # The HMM oracle from Cell 4\n",
    "        self.steps_done = 0\n",
    "\n",
    "    def select_action(self, state_dict, valid_actions_mask):\n",
    "        \"\"\"\n",
    "        Chooses an action (int 0-25) using an epsilon-greedy policy.\n",
    "        \"\"\"\n",
    "        sample = random.random()\n",
    "        eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "                        np.exp(-1. * self.steps_done / EPS_DECAY)\n",
    "        self.steps_done += 1\n",
    "        \n",
    "        if sample > eps_threshold:\n",
    "            # --- Exploitation ---\n",
    "            with torch.no_grad():\n",
    "                q_values = self.policy_net(state_dict) # Shape: [1, 26]\n",
    "                \n",
    "                # --- ACTION MASKING ---\n",
    "                q_values[0, ~valid_actions_mask] = -float('inf')\n",
    "                \n",
    "                action_tensor = q_values.max(1)[1] # Get index of max Q-value\n",
    "                return action_tensor.view(1, 1)\n",
    "        else:\n",
    "            # --- Exploration ---\n",
    "            valid_indices = torch.where(valid_actions_mask)[0].tolist()\n",
    "            if not valid_indices: \n",
    "                return torch.tensor([[0]], device=device, dtype=torch.long)\n",
    "            \n",
    "            chosen_action = random.choice(valid_indices)\n",
    "            return torch.tensor([[chosen_action]], device=device, dtype=torch.long)\n",
    "\n",
    "    def learn(self):\n",
    "        if len(self.buffer) < BATCH_SIZE:\n",
    "            return \n",
    "        \n",
    "        experiences = self.buffer.sample(BATCH_SIZE)\n",
    "        batch = Experience(*zip(*experiences))\n",
    "\n",
    "        # --- 1. Prepare Batch Tensors (SIMPLIFIED) ---\n",
    "        state_batch = {\n",
    "            \"guessed\": torch.cat([s[\"guessed\"] for s in batch.state]),\n",
    "            \"lives\": torch.cat([s[\"lives\"] for s in batch.state]),\n",
    "            \"hmm\": torch.cat([s[\"hmm\"] for s in batch.state])\n",
    "        }\n",
    "        next_state_batch = {\n",
    "            \"guessed\": torch.cat([s[\"guessed\"] for s in batch.next_state]),\n",
    "            \"lives\": torch.cat([s[\"lives\"] for s in batch.next_state]),\n",
    "            \"hmm\": torch.cat([s[\"hmm\"] for s in batch.next_state])\n",
    "        }\n",
    "        \n",
    "        action_batch = torch.cat(batch.action)\n",
    "        reward_batch = torch.tensor(batch.reward, dtype=torch.float, device=device)\n",
    "        done_batch = torch.tensor(batch.done, dtype=torch.bool, device=device)\n",
    "        \n",
    "        # --- 2. Calculate Q(s, a) ---\n",
    "        state_action_values = self.policy_net(state_batch).gather(1, action_batch).squeeze()\n",
    "\n",
    "        # --- 3. Calculate Target Q-value ---\n",
    "        next_q_values = self.target_net(next_state_batch)\n",
    "        \n",
    "        next_valid_actions_mask = torch.stack(batch.valid_actions)\n",
    "        next_q_values[~next_valid_actions_mask] = -float('inf') \n",
    "        \n",
    "        next_state_max_q = next_q_values.max(1)[0]\n",
    "        next_state_max_q[done_batch] = 0.0 \n",
    "        expected_state_action_values = (next_state_max_q * GAMMA) + reward_batch\n",
    "\n",
    "        # --- 4. Calculate Loss ---\n",
    "        loss = F.smooth_l1_loss(state_action_values, expected_state_action_values)\n",
    "        \n",
    "        # --- 5. Optimize ---\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        for param in self.policy_net.parameters():\n",
    "            param.grad.data.clamp_(-1, 1) # Gradient clipping\n",
    "        self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T08:32:01.520342Z",
     "iopub.status.busy": "2025-11-03T08:32:01.519740Z",
     "iopub.status.idle": "2025-11-03T08:35:40.162222Z",
     "shell.execute_reply": "2025-11-03T08:35:40.161529Z",
     "shell.execute_reply.started": "2025-11-03T08:32:01.520317Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50000 words from corpus.txt for training.\n",
      "--- Starting DQN Training for 20000 Episodes ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f4b9013dcf947d1a9a17c1268841a52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- üèÅ Training Complete ---\n",
      "Model saved to dqn_hangman_model.pth\n"
     ]
    }
   ],
   "source": [
    "# --- Training Setup ---\n",
    "# (Make sure 'oracle' (Trigram HMM) from Cell 4 is initialized)\n",
    "# (Make sure 'corpus_words' from Cell 2 is loaded, or load them now)\n",
    "\n",
    "if 'oracle' not in locals():\n",
    "    print(\"ERROR: 'oracle' is not initialized. Please run Cell 4.\")\n",
    "if 'words_by_length' not in locals():\n",
    "    print(\"ERROR: 'words_by_length' is not initialized. Please run Cell 2.\")\n",
    "\n",
    "# --- 1. Load Corpus Words ---\n",
    "# We train the agent on the same data the HMM was trained on.\n",
    "try:\n",
    "    with open(\"corpus.txt\", 'r') as f:\n",
    "        train_words = [word.strip().upper() for word in f if word.strip()]\n",
    "    print(f\"Loaded {len(train_words)} words from corpus.txt for training.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"ERROR: corpus.txt not found.\")\n",
    "    train_words = None\n",
    "\n",
    "if train_words:\n",
    "    # --- 2. Set Hyperparameters ---\n",
    "    # 5,000 was not enough. Let's try 20,000.\n",
    "    # You may need to run 50,000+ to see strong results.\n",
    "    NUM_EPISODES = 20000 \n",
    "    \n",
    "    # (These are from your Cell 12)\n",
    "    TARGET_UPDATE = 10\n",
    "    \n",
    "    # --- 3. Initialize Env and Agent ---\n",
    "    # IMPORTANT: We initialize the env with our TRAINING words\n",
    "    env = HangmanEnv(train_words) \n",
    "    agent = DQNAgent(oracle)\n",
    "    \n",
    "    # (Optional: Use the stability fixes we discussed)\n",
    "    agent.LR = 1e-4\n",
    "    agent.optimizer = optim.Adam(agent.policy_net.parameters(), lr=agent.LR)\n",
    "    \n",
    "    episode_rewards = []\n",
    "    print(f\"--- Starting DQN Training for {NUM_EPISODES} Episodes ---\")\n",
    "    \n",
    "    pbar = tqdm(range(NUM_EPISODES))\n",
    "    for i_episode in pbar:\n",
    "        (pattern, guessed, lives) = env.reset()\n",
    "        state = get_state_tensor(pattern, guessed, lives, agent.oracle)\n",
    "        total_reward = 0\n",
    "        \n",
    "        # Max turns per game\n",
    "        for t in range(MAX_WORD_LEN + 10): \n",
    "            valid_actions_mask = get_valid_actions_mask(guessed)\n",
    "            action_tensor = agent.select_action(state, valid_actions_mask)\n",
    "            action_char = INDEX_TO_CHAR[action_tensor.item()]\n",
    "            \n",
    "            (next_pattern, next_guessed, next_lives), reward, done = env.step(action_char)\n",
    "            \n",
    "            total_reward += reward\n",
    "            \n",
    "            next_state = get_state_tensor(next_pattern, next_guessed, next_lives, agent.oracle)\n",
    "            next_valid_actions_mask = get_valid_actions_mask(next_guessed)\n",
    "            \n",
    "            agent.buffer.push(state, action_tensor, reward, next_state, done, next_valid_actions_mask)\n",
    "            \n",
    "            state = next_state\n",
    "            guessed = next_guessed\n",
    "            \n",
    "            agent.learn()\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        episode_rewards.append(total_reward)\n",
    "        \n",
    "        # --- Log Progress ---\n",
    "        if (i_episode + 1) % 100 == 0:\n",
    "            avg_reward = np.mean(episode_rewards[-100:])\n",
    "            pbar.set_description(f\"Episode {i_episode+1}/{NUM_EPISODES} | Avg Reward (100ep): {avg_reward:.2f}\")\n",
    "            \n",
    "        # Update the target network\n",
    "        if i_episode % TARGET_UPDATE == 0:\n",
    "            agent.target_net.load_state_dict(agent.policy_net.state_dict())\n",
    "\n",
    "    print(\"--- üèÅ Training Complete ---\")\n",
    "    \n",
    "    # Save the trained model\n",
    "    torch.save(agent.policy_net.state_dict(), \"dqn_hangman_model.pth\")\n",
    "    print(\"Model saved to dqn_hangman_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T08:35:57.106104Z",
     "iopub.status.busy": "2025-11-03T08:35:57.105622Z",
     "iopub.status.idle": "2025-11-03T08:36:09.165452Z",
     "shell.execute_reply": "2025-11-03T08:36:09.164837Z",
     "shell.execute_reply.started": "2025-11-03T08:35:57.106075Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Evaluation with Trained DQN Agent: 2000 games on test.txt ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b791aca434a45d8837fca466aee45c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Evaluation Complete ---\n",
      "\n",
      "--- üìä Final Results (DQN Agent on test.txt) ---\n",
      "**Final Score:** -56532.00\n",
      "------------------------------\n",
      "Total Games Played:     2000\n",
      "Total Games Won:        338 (16.90%)\n",
      "------------------------------\n",
      "Total Wrong Guesses:    11374 (Avg: 5.69 per game)\n",
      "Total Repeated Guesses: 0 (Avg: 0.00 per game)\n",
      "------------------------------\n",
      "Score from Wins:        + 338.00\n",
      "Penalty from Wrongs:    - 56870.00\n",
      "Penalty from Repeats:   - 0.00\n"
     ]
    }
   ],
   "source": [
    "# --- Final Evaluation ---\n",
    "# (Make sure 'test_words' from Cell 6 is loaded)\n",
    "# (Make sure 'oracle' from Cell 4 is loaded)\n",
    "\n",
    "if 'test_words' not in locals():\n",
    "    print(\"ERROR: 'test_words' not loaded. Please run Cell 6.\")\n",
    "if 'oracle' not in locals():\n",
    "    print(\"ERROR: 'oracle' not initialized. Please run Cell 4.\")\n",
    "\n",
    "# --- 1. Load the Trained Agent ---\n",
    "eval_agent = DQNAgent(oracle)\n",
    "eval_agent.policy_net.load_state_dict(torch.load(\"dqn_hangman_model.pth\", map_location=device))\n",
    "eval_agent.policy_net.eval() # Set to evaluation mode\n",
    "\n",
    "# --- 2. Create the Evaluation Environment ---\n",
    "# IMPORTANT: We evaluate on the TEST words\n",
    "eval_env = HangmanEnv(test_words)\n",
    "\n",
    "NUM_GAMES = 2000 # As specified in the PDF\n",
    "MAX_LIVES = 6\n",
    "\n",
    "total_games_won = 0\n",
    "total_wrong_guesses = 0\n",
    "total_repeated_guesses = 0\n",
    "\n",
    "print(f\"\\n--- Starting Evaluation with Trained DQN Agent: {NUM_GAMES} games on test.txt ---\")\n",
    "\n",
    "pbar_eval = tqdm(range(NUM_GAMES))\n",
    "for i in pbar_eval:\n",
    "    (pattern, guessed, lives) = eval_env.reset()\n",
    "    done = False\n",
    "    \n",
    "    game_wrong_guesses = 0\n",
    "    game_repeated_guesses = 0\n",
    "    \n",
    "    while not done:\n",
    "        state = get_state_tensor(pattern, guessed, lives, eval_agent.oracle)\n",
    "        valid_actions_mask = get_valid_actions_mask(guessed)\n",
    "        \n",
    "        # --- Pure Exploitation (No Epsilon) ---\n",
    "        with torch.no_grad():\n",
    "            q_values = eval_agent.policy_net(state) # Shape [1, 26]\n",
    "            q_values[0, ~valid_actions_mask] = -float('inf') \n",
    "            action_tensor = q_values.max(1)[1]\n",
    "            \n",
    "        action_char = INDEX_TO_CHAR[action_tensor.item()]\n",
    "        \n",
    "        # --- Manually track for PDF score ---\n",
    "        # We check *before* the step\n",
    "        if action_char in guessed:\n",
    "            game_repeated_guesses += 1\n",
    "        elif action_char not in eval_env.secret_word:\n",
    "            game_wrong_guesses += 1\n",
    "        \n",
    "        # Take the step\n",
    "        (next_pattern, next_guessed, next_lives), reward, done = eval_env.step(action_char)\n",
    "        pattern, guessed, lives = next_pattern, next_guessed, next_lives\n",
    "\n",
    "    # --- End of Game ---\n",
    "    if lives > 0: # Game was won\n",
    "        total_games_won += 1\n",
    "        \n",
    "    total_wrong_guesses += game_wrong_guesses\n",
    "    total_repeated_guesses += game_repeated_guesses\n",
    "\n",
    "print(\"--- Evaluation Complete ---\")\n",
    "\n",
    "# --- 3. Calculate Final Results using PDF Formula ---\n",
    "success_rate = total_games_won / NUM_GAMES\n",
    "\n",
    "# Score = (Success Rate * 2000) - (Total Wrong Guesses * 5) - (Total Repeated Guesses * 2)\n",
    "score_from_wins = success_rate * 2000 # This is just total_games_won\n",
    "penalty_from_wrongs = total_wrong_guesses * 5\n",
    "penalty_from_repeats = total_repeated_guesses * 2\n",
    "\n",
    "final_score = score_from_wins - penalty_from_wrongs - penalty_from_repeats\n",
    "\n",
    "# --- 4. Print Report ---\n",
    "print(\"\\n--- üìä Final Results (DQN Agent on test.txt) ---\")\n",
    "print(f\"**Final Score:** {final_score:.2f}\")\n",
    "print(\"------------------------------\")\n",
    "print(f\"Total Games Played:     {NUM_GAMES}\")\n",
    "print(f\"Total Games Won:        {total_games_won} ({success_rate * 100:.2f}%)\")\n",
    "print(\"------------------------------\")\n",
    "print(f\"Total Wrong Guesses:    {total_wrong_guesses} (Avg: {total_wrong_guesses / NUM_GAMES:.2f} per game)\")\n",
    "print(f\"Total Repeated Guesses: {total_repeated_guesses} (Avg: {total_repeated_guesses / NUM_GAMES:.2f} per game)\")\n",
    "print(\"------------------------------\")\n",
    "print(f\"Score from Wins:        + {score_from_wins:.2f}\")\n",
    "print(f\"Penalty from Wrongs:    - {penalty_from_wrongs:.2f}\")\n",
    "print(f\"Penalty from Repeats:   - {penalty_from_repeats:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéÆ Interactive Hangman Demo:\n",
      "\n",
      "============================================================\n",
      "============================================================\n",
      "üéØ SECRET WORD: ***** (5 letters)\n",
      "üíö Lives: 6/6\n",
      "============================================================\n",
      "\n",
      "--- Turn 1 ---\n",
      "Pattern: _____\n",
      "Guessed: None\n",
      "Lives: ‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è\n",
      "\n",
      "üîç Top 5 Predictions:\n",
      "  1. 'A': Combined=0.1055 (HMM=0.1063, DQN=0.0214)\n",
      "  2. 'E': Combined=0.0967 (HMM=0.0976, DQN=0.0010)\n",
      "  3. 'O': Combined=0.0686 (HMM=0.0692, DQN=0.0054)\n",
      "  4. 'R': Combined=0.0666 (HMM=0.0672, DQN=0.0043)\n",
      "  5. 'I': Combined=0.0630 (HMM=0.0633, DQN=0.0325)\n",
      "\n",
      "‚úÖ CORRECT! 'A' is in the word!\n",
      "   New pattern: A____\n",
      "\n",
      "--- Turn 2 ---\n",
      "Pattern: A____\n",
      "Guessed: ['A']\n",
      "Lives: ‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è\n",
      "\n",
      "üîç Top 5 Predictions:\n",
      "  1. 'E': Combined=0.0978 (HMM=0.0987, DQN=0.0055)\n",
      "  2. 'D': Combined=0.0766 (HMM=0.0771, DQN=0.0294)\n",
      "  3. 'R': Combined=0.0758 (HMM=0.0765, DQN=0.0012)\n",
      "  4. 'L': Combined=0.0735 (HMM=0.0742, DQN=0.0017)\n",
      "  5. 'N': Combined=0.0709 (HMM=0.0708, DQN=0.0747)\n",
      "\n",
      "‚úÖ CORRECT! 'E' is in the word!\n",
      "   New pattern: A___E\n",
      "\n",
      "--- Turn 3 ---\n",
      "Pattern: A___E\n",
      "Guessed: ['A', 'E']\n",
      "Lives: ‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è\n",
      "\n",
      "üîç Top 5 Predictions:\n",
      "  1. 'D': Combined=0.1129 (HMM=0.1133, DQN=0.0711)\n",
      "  2. 'M': Combined=0.0902 (HMM=0.0906, DQN=0.0523)\n",
      "  3. 'R': Combined=0.0869 (HMM=0.0877, DQN=0.0017)\n",
      "  4. 'L': Combined=0.0861 (HMM=0.0870, DQN=0.0013)\n",
      "  5. 'N': Combined=0.0759 (HMM=0.0755, DQN=0.1111)\n",
      "\n",
      "‚ùå WRONG! 'D' is not in the word.\n",
      "   Lives remaining: 5/6\n",
      "\n",
      "--- Turn 4 ---\n",
      "Pattern: A___E\n",
      "Guessed: ['A', 'D', 'E']\n",
      "Lives: ‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏èüñ§\n",
      "\n",
      "üîç Top 5 Predictions:\n",
      "  1. 'M': Combined=0.1017 (HMM=0.1022, DQN=0.0499)\n",
      "  2. 'R': Combined=0.0980 (HMM=0.0990, DQN=0.0025)\n",
      "  3. 'L': Combined=0.0971 (HMM=0.0981, DQN=0.0034)\n",
      "  4. 'N': Combined=0.0859 (HMM=0.0852, DQN=0.1581)\n",
      "  5. 'T': Combined=0.0609 (HMM=0.0609, DQN=0.0663)\n",
      "\n",
      "‚ùå WRONG! 'M' is not in the word.\n",
      "   Lives remaining: 4/6\n",
      "\n",
      "--- Turn 5 ---\n",
      "Pattern: A___E\n",
      "Guessed: ['A', 'D', 'E', 'M']\n",
      "Lives: ‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏èüñ§üñ§\n",
      "\n",
      "üîç Top 5 Predictions:\n",
      "  1. 'R': Combined=0.1091 (HMM=0.1102, DQN=0.0027)\n",
      "  2. 'L': Combined=0.1082 (HMM=0.1093, DQN=0.0049)\n",
      "  3. 'N': Combined=0.0961 (HMM=0.0949, DQN=0.2177)\n",
      "  4. 'T': Combined=0.0678 (HMM=0.0678, DQN=0.0658)\n",
      "  5. 'I': Combined=0.0667 (HMM=0.0669, DQN=0.0463)\n",
      "\n",
      "‚ùå WRONG! 'R' is not in the word.\n",
      "   Lives remaining: 3/6\n",
      "\n",
      "--- Turn 6 ---\n",
      "Pattern: A___E\n",
      "Guessed: ['A', 'D', 'E', 'M', 'R']\n",
      "Lives: ‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏èüñ§üñ§üñ§\n",
      "\n",
      "üîç Top 5 Predictions:\n",
      "  1. 'L': Combined=0.1217 (HMM=0.1228, DQN=0.0139)\n",
      "  2. 'N': Combined=0.1066 (HMM=0.1066, DQN=0.1002)\n",
      "  3. 'T': Combined=0.0759 (HMM=0.0762, DQN=0.0455)\n",
      "  4. 'I': Combined=0.0752 (HMM=0.0752, DQN=0.0805)\n",
      "  5. 'G': Combined=0.0712 (HMM=0.0712, DQN=0.0638)\n",
      "\n",
      "‚úÖ CORRECT! 'L' is in the word!\n",
      "   New pattern: A__LE\n",
      "\n",
      "--- Turn 7 ---\n",
      "Pattern: A__LE\n",
      "Guessed: ['A', 'D', 'E', 'L', 'M', 'R']\n",
      "Lives: ‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏èüñ§üñ§üñ§\n",
      "\n",
      "üîç Top 5 Predictions:\n",
      "  1. 'G': Combined=0.1177 (HMM=0.1184, DQN=0.0518)\n",
      "  2. 'B': Combined=0.1175 (HMM=0.1187, DQN=0.0020)\n",
      "  3. 'N': Combined=0.1175 (HMM=0.1182, DQN=0.0412)\n",
      "  4. 'S': Combined=0.0880 (HMM=0.0887, DQN=0.0176)\n",
      "  5. 'W': Combined=0.0683 (HMM=0.0690, DQN=0.0006)\n",
      "\n",
      "‚ùå WRONG! 'G' is not in the word.\n",
      "   Lives remaining: 2/6\n",
      "\n",
      "--- Turn 8 ---\n",
      "Pattern: A__LE\n",
      "Guessed: ['A', 'D', 'E', 'G', 'L', 'M', 'R']\n",
      "Lives: ‚ù§Ô∏è‚ù§Ô∏èüñ§üñ§üñ§üñ§\n",
      "\n",
      "üîç Top 5 Predictions:\n",
      "  1. 'N': Combined=0.1334 (HMM=0.1341, DQN=0.0642)\n",
      "  2. 'B': Combined=0.1333 (HMM=0.1346, DQN=0.0021)\n",
      "  3. 'S': Combined=0.0998 (HMM=0.1006, DQN=0.0239)\n",
      "  4. 'W': Combined=0.0775 (HMM=0.0782, DQN=0.0007)\n",
      "  5. 'U': Combined=0.0681 (HMM=0.0679, DQN=0.0867)\n",
      "\n",
      "‚ùå WRONG! 'N' is not in the word.\n",
      "   Lives remaining: 1/6\n",
      "\n",
      "--- Turn 9 ---\n",
      "Pattern: A__LE\n",
      "Guessed: ['A', 'D', 'E', 'G', 'L', 'M', 'N', 'R']\n",
      "Lives: ‚ù§Ô∏èüñ§üñ§üñ§üñ§üñ§\n",
      "\n",
      "üîç Top 5 Predictions:\n",
      "  1. 'B': Combined=0.1539 (HMM=0.1555, DQN=0.0017)\n",
      "  2. 'S': Combined=0.1154 (HMM=0.1162, DQN=0.0384)\n",
      "  3. 'W': Combined=0.0894 (HMM=0.0903, DQN=0.0008)\n",
      "  4. 'U': Combined=0.0785 (HMM=0.0784, DQN=0.0888)\n",
      "  5. 'P': Combined=0.0776 (HMM=0.0780, DQN=0.0358)\n",
      "\n",
      "‚ùå WRONG! 'B' is not in the word.\n",
      "   Lives remaining: 0/6\n",
      "\n",
      "============================================================\n",
      "üíÄ GAME OVER! Failed to guess the word.\n",
      "   The word was: APPLE\n",
      "   Final pattern: A__LE\n",
      "   Wrong guesses: 6\n",
      "============================================================\n",
      "\n",
      "üìä Game Summary:\n",
      "   Result: ‚ùå Lost\n",
      "   Total turns: 9\n",
      "   Wrong guesses: 6\n",
      "   Efficiency: 33.3% correct\n"
     ]
    }
   ],
   "source": [
    "## üéÆ Interactive Demo: Watch the Hybrid Agent Play!\n",
    "\n",
    "# Let the user input a word and watch the agent solve it step-by-step\n",
    "\n",
    "def demo_game(secret_word, agent, oracle, max_lives=6, verbose=True):\n",
    "    \"\"\"\n",
    "    Plays a single Hangman game and shows the decision-making process.\n",
    "    \"\"\"\n",
    "    secret_word = secret_word.upper().strip()\n",
    "    word_length = len(secret_word)\n",
    "    pattern = \"_\" * word_length\n",
    "    guessed_letters = set()\n",
    "    lives = max_lives\n",
    "    \n",
    "    turn = 0\n",
    "    game_history = []\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"üéØ SECRET WORD: {'*' * word_length} ({word_length} letters)\")\n",
    "        print(f\"üíö Lives: {lives}/{max_lives}\")\n",
    "        print(\"=\" * 60)\n",
    "    \n",
    "    while lives > 0 and \"_\" in pattern:\n",
    "        turn += 1\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\n--- Turn {turn} ---\")\n",
    "            print(f\"Pattern: {pattern}\")\n",
    "            print(f\"Guessed: {sorted(guessed_letters) if guessed_letters else 'None'}\")\n",
    "            print(f\"Lives: {'‚ù§Ô∏è' * lives}{'üñ§' * (max_lives - lives)}\")\n",
    "        \n",
    "        # Get state and predictions\n",
    "        state = get_state_tensor(pattern, guessed_letters, lives, oracle)\n",
    "        valid_actions_mask = get_valid_actions_mask(guessed_letters)\n",
    "        \n",
    "        # Get HMM probabilities\n",
    "        hmm_probs = oracle.get_letter_probabilities(pattern, guessed_letters)\n",
    "        \n",
    "        # Get DQN Q-values\n",
    "        with torch.no_grad():\n",
    "            q_values = agent.policy_net(state)\n",
    "            q_values_masked = q_values.clone()\n",
    "            q_values_masked[0, ~valid_actions_mask] = -float('inf')\n",
    "            q_probs = torch.softmax(q_values_masked[0], dim=0).cpu().numpy()\n",
    "        \n",
    "        # Combine: 99% HMM + 1% DQN\n",
    "        hmm_vec = np.array([hmm_probs.get(char, 0.0) for char in ALPHABET])\n",
    "        combined_probs = 0.99 * hmm_vec + 0.01 * q_probs\n",
    "        combined_probs[~valid_actions_mask.cpu().numpy()] = 0\n",
    "        \n",
    "        # Get top predictions\n",
    "        if verbose:\n",
    "            print(\"\\nüîç Top 5 Predictions:\")\n",
    "            top_indices = np.argsort(combined_probs)[-5:][::-1]\n",
    "            for i, idx in enumerate(top_indices, 1):\n",
    "                char = ALPHABET[idx]\n",
    "                hmm_p = hmm_vec[idx]\n",
    "                q_p = q_probs[idx]\n",
    "                combined_p = combined_probs[idx]\n",
    "                print(f\"  {i}. '{char}': Combined={combined_p:.4f} (HMM={hmm_p:.4f}, DQN={q_p:.4f})\")\n",
    "        \n",
    "        # Make decision\n",
    "        if combined_probs.sum() > 0:\n",
    "            action_idx = np.argmax(combined_probs)\n",
    "        else:\n",
    "            action_idx = np.argmax(hmm_vec)\n",
    "        \n",
    "        guess = ALPHABET[action_idx]\n",
    "        guessed_letters.add(guess)\n",
    "        \n",
    "        # Check if correct\n",
    "        if guess in secret_word:\n",
    "            # Update pattern\n",
    "            new_pattern = list(pattern)\n",
    "            for i in range(word_length):\n",
    "                if secret_word[i] == guess:\n",
    "                    new_pattern[i] = guess\n",
    "            pattern = \"\".join(new_pattern)\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"\\n‚úÖ CORRECT! '{guess}' is in the word!\")\n",
    "                print(f\"   New pattern: {pattern}\")\n",
    "            \n",
    "            game_history.append({\n",
    "                'turn': turn,\n",
    "                'guess': guess,\n",
    "                'correct': True,\n",
    "                'pattern': pattern,\n",
    "                'lives': lives\n",
    "            })\n",
    "            \n",
    "            if \"_\" not in pattern:\n",
    "                if verbose:\n",
    "                    print(\"\\n\" + \"=\" * 60)\n",
    "                    print(f\"üéâ VICTORY! Word solved in {turn} guesses!\")\n",
    "                    print(f\"   Final word: {pattern}\")\n",
    "                    print(f\"   Lives remaining: {lives}/{max_lives}\")\n",
    "                    print(\"=\" * 60)\n",
    "                return True, turn, max_lives - lives, game_history\n",
    "        else:\n",
    "            lives -= 1\n",
    "            if verbose:\n",
    "                print(f\"\\n‚ùå WRONG! '{guess}' is not in the word.\")\n",
    "                print(f\"   Lives remaining: {lives}/{max_lives}\")\n",
    "            \n",
    "            game_history.append({\n",
    "                'turn': turn,\n",
    "                'guess': guess,\n",
    "                'correct': False,\n",
    "                'pattern': pattern,\n",
    "                'lives': lives\n",
    "            })\n",
    "            \n",
    "            if lives == 0:\n",
    "                if verbose:\n",
    "                    print(\"\\n\" + \"=\" * 60)\n",
    "                    print(f\"üíÄ GAME OVER! Failed to guess the word.\")\n",
    "                    print(f\"   The word was: {secret_word}\")\n",
    "                    print(f\"   Final pattern: {pattern}\")\n",
    "                    print(f\"   Wrong guesses: {max_lives}\")\n",
    "                    print(\"=\" * 60)\n",
    "                return False, turn, max_lives, game_history\n",
    "    \n",
    "    return False, turn, max_lives - lives, game_history\n",
    "\n",
    "\n",
    "# === INTERACTIVE DEMO ===\n",
    "\n",
    "print(\"üéÆ Interactive Hangman Demo:\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# Example words to try\n",
    "demo_word = input(\"\\nEnter a word for the agent to guess (or press Enter for 'PYTHON'): \").strip()\n",
    "\n",
    "if not demo_word:\n",
    "    demo_word = \"PYTHON\"\n",
    "    print(f\"Using default word: {demo_word}\")\n",
    "\n",
    "# Validate input\n",
    "if not demo_word.isalpha():\n",
    "    print(\"‚ùå Error: Word must contain only letters!\")\n",
    "elif len(demo_word) not in oracle.models:\n",
    "    print(f\"‚ùå Error: No HMM model trained for {len(demo_word)}-letter words!\")\n",
    "    print(f\"   Available lengths: {sorted(oracle.models.keys())}\")\n",
    "else:\n",
    "    # Check if agent and oracle are initialized\n",
    "    if 'agent' not in locals() or 'oracle' not in locals():\n",
    "        print(\"‚ö†Ô∏è  Warning: Agent not trained yet. Run the training cell first!\")\n",
    "        print(\"   For now, using pure HMM predictions...\")\n",
    "        \n",
    "        # Fallback to pure HMM demo\n",
    "        def demo_game_hmm_only(secret_word, oracle, max_lives=6):\n",
    "            secret_word = secret_word.upper().strip()\n",
    "            word_length = len(secret_word)\n",
    "            pattern = \"_\" * word_length\n",
    "            guessed_letters = set()\n",
    "            lives = max_lives\n",
    "            turn = 0\n",
    "            \n",
    "            print(\"=\" * 60)\n",
    "            print(f\"üéØ SECRET WORD: {'*' * word_length} ({word_length} letters)\")\n",
    "            print(f\"üíö Lives: {lives}/{max_lives}\")\n",
    "            print(\"=\" * 60)\n",
    "            \n",
    "            while lives > 0 and \"_\" in pattern:\n",
    "                turn += 1\n",
    "                print(f\"\\n--- Turn {turn} ---\")\n",
    "                print(f\"Pattern: {pattern}\")\n",
    "                print(f\"Guessed: {sorted(guessed_letters) if guessed_letters else 'None'}\")\n",
    "                print(f\"Lives: {'‚ù§Ô∏è' * lives}{'üñ§' * (max_lives - lives)}\")\n",
    "                \n",
    "                # Get HMM probabilities\n",
    "                hmm_probs = oracle.get_letter_probabilities(pattern, guessed_letters)\n",
    "                \n",
    "                if not hmm_probs:\n",
    "                    print(\"\\n‚ùå No valid guesses remaining!\")\n",
    "                    break\n",
    "                \n",
    "                # Show top 5\n",
    "                print(\"\\nüîç Top 5 HMM Predictions:\")\n",
    "                for i, (char, prob) in enumerate(sorted(hmm_probs.items(), key=lambda x: x[1], reverse=True)[:5], 1):\n",
    "                    print(f\"  {i}. '{char}': {prob:.4f}\")\n",
    "                \n",
    "                # Make guess\n",
    "                guess = max(hmm_probs, key=hmm_probs.get)\n",
    "                guessed_letters.add(guess)\n",
    "                \n",
    "                if guess in secret_word:\n",
    "                    new_pattern = list(pattern)\n",
    "                    for i in range(word_length):\n",
    "                        if secret_word[i] == guess:\n",
    "                            new_pattern[i] = guess\n",
    "                    pattern = \"\".join(new_pattern)\n",
    "                    print(f\"\\n‚úÖ CORRECT! '{guess}' is in the word!\")\n",
    "                    print(f\"   New pattern: {pattern}\")\n",
    "                    \n",
    "                    if \"_\" not in pattern:\n",
    "                        print(\"\\n\" + \"=\" * 60)\n",
    "                        print(f\"üéâ VICTORY! Word solved in {turn} guesses!\")\n",
    "                        print(f\"   Final word: {pattern}\")\n",
    "                        print(f\"   Lives remaining: {lives}/{max_lives}\")\n",
    "                        print(\"=\" * 60)\n",
    "                        return\n",
    "                else:\n",
    "                    lives -= 1\n",
    "                    print(f\"\\n‚ùå WRONG! '{guess}' is not in the word.\")\n",
    "                    print(f\"   Lives remaining: {lives}/{max_lives}\")\n",
    "                    \n",
    "                    if lives == 0:\n",
    "                        print(\"\\n\" + \"=\" * 60)\n",
    "                        print(f\"üíÄ GAME OVER! Failed to guess the word.\")\n",
    "                        print(f\"   The word was: {secret_word}\")\n",
    "                        print(f\"   Final pattern: {pattern}\")\n",
    "                        print(\"=\" * 60)\n",
    "                        return\n",
    "        \n",
    "        demo_game_hmm_only(demo_word, oracle)\n",
    "    else:\n",
    "        # Run the full demo with trained agent\n",
    "        won, turns, wrong_guesses, history = demo_game(demo_word, agent, oracle)\n",
    "        \n",
    "        # Summary\n",
    "        print(\"\\nüìä Game Summary:\")\n",
    "        print(f\"   Result: {'‚úÖ Won' if won else '‚ùå Lost'}\")\n",
    "        print(f\"   Total turns: {turns}\")\n",
    "        print(f\"   Wrong guesses: {wrong_guesses}\")\n",
    "        print(f\"   Efficiency: {(turns - wrong_guesses) / turns * 100:.1f}% correct\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8636677,
     "sourceId": 13593116,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
